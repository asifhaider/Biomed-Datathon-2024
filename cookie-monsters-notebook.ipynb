{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution Notebook: Cookie Monsters\n",
    "\n",
    "This combined notebook is outlined as follows:\n",
    "\n",
    "1. Part 0 outlines some data augmentation logic that has been implemented to support further experiment later on, but not included or directly used in the working solutions submitted below. Refer to the presentation slide for more details about this. \n",
    "2. Part 1 contains the machine learning algorithms tried out which result in the best private score obtained.\n",
    "3. Part 2 contains the deep learning approcach taken resulting in the best public score and final leaderboard position. \n",
    "\n",
    "We recommend reproducing part 1 and part 2 separately in different notebooks or commenting out the other one. This notebook puts all the codes together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Augmentation Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data augmentation (pitch, speed, noise, time stretch)\n",
    "# RANDOM_STATE = 42   # for reproducibility\n",
    "\n",
    "# def pitch_shift(data, sampling_rate=4000, pitch_factor=2.0):\n",
    "#     return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "# def time_stretch(data, stretch_factor):\n",
    "#     return librosa.effects.time_stretch(data, stretch_factor)\n",
    "\n",
    "# def add_noise(data, noise_factor):\n",
    "#     noise = np.random.randn(len(data))\n",
    "#     data_noise = data + noise_factor * noise\n",
    "#     return data_noise\n",
    "\n",
    "# def speed_change(data, speed_factor):\n",
    "#     return librosa.effects.time_stretch(data, speed_factor)\n",
    "\n",
    "# # data augmentation using time stretch\n",
    "\n",
    "# # for each patient id, we will create a time stretch of 0.8 and 1.2 and add two new rows to the dataframe with the new audio files and patient id as previous patient id + \"i\" where i is 1 or 2\n",
    "\n",
    "# # keep the target columns the same\n",
    "\n",
    "# import soundfile as sf\n",
    "# import librosa\n",
    "\n",
    "# target_classes = ['AS', 'AR', 'MR', 'MS', 'N']\n",
    "\n",
    "# time_stretch_list = []\n",
    "# for k in range(len(train_df)):\n",
    "#     data = train_df.iloc[k]\n",
    "#     # print(data)\n",
    "#     # Get the original patient id and the original labels\n",
    "#     original_patiend_id = data[\"patient_id\"]\n",
    "#     original_labels = data[target_classes].values\n",
    "\n",
    "        \n",
    "#     time_stretch_list_08 = []\n",
    "#     time_stretch_list_12 = []\n",
    "\n",
    "#     #new patient id\n",
    "#     new_patient_id_1 = original_patiend_id + \"_1\"\n",
    "#     new_patient_id_2 = original_patiend_id + \"_2\"\n",
    "\n",
    "#     for i in range(8):\n",
    "#         column_name = f\"recording_{i+1}\"\n",
    "#         # fetch the audio file\n",
    "#         audio_file = data[column_name]\n",
    "#         file_path = train_dir_path + audio_file + \".wav\"\n",
    "#         aud, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "#         # create a time stretch of 0.8 and 1.2\n",
    "#         time_stretch_audio_08 = librosa.effects.time_stretch(aud, rate = 0.8)\n",
    "#         time_stretch_audio_12 = librosa.effects.time_stretch(aud, rate = 1.2)\n",
    "\n",
    "#         new_audio_file_08 = audio_file + \"_time_stretch_08\"\n",
    "#         new_audio_file_12 = audio_file + \"_time_stretch_12\"\n",
    "\n",
    "#         save_location_08 = train_dir_path + new_audio_file_08 + \".wav\"\n",
    "#         save_location_12 = train_dir_path + new_audio_file_12 + \".wav\"\n",
    "\n",
    "#         sf.write(save_location_08, time_stretch_audio_08, sr)\n",
    "#         sf.write(save_location_12, time_stretch_audio_12, sr)\n",
    "\n",
    "#         time_stretch_list_08.append(new_audio_file_08)\n",
    "#         time_stretch_list_12.append(new_audio_file_12)\n",
    "    \n",
    "#     # add the new patient id, original labels and the new audio files to the dataframe\n",
    "#     #concatenate the original labels with the new audio files\n",
    "    \n",
    "#     # convert new_patient_id_1, new_patient_id_2 to a numpy array\n",
    "#     new_patient_id_1 = np.array([new_patient_id_1])\n",
    "#     new_patient_id_2 = np.array([new_patient_id_2])\n",
    "#     new_list = np.concatenate((new_patient_id_1, original_labels, time_stretch_list_08))\n",
    "#     time_stretch_list.append(new_list)\n",
    "#     new_list = np.concatenate((new_patient_id_2, original_labels, time_stretch_list_12))\n",
    "#     time_stretch_list.append(new_list)\n",
    "\n",
    "# # data augmentation using noise\n",
    "\n",
    "# # for each patient id, create a new audio file with added noise and add a new row to the dataframe with the new audio file and patient id as previous patient id + \"i\" where i is 1 or 2\n",
    "\n",
    "# # keep the target columns the same\n",
    "\n",
    "# def add_noise(data, noise_factor):\n",
    "#     noise = np.random.randn(len(data))\n",
    "#     data_noise = data + noise_factor * noise\n",
    "#     return data_noise\n",
    "\n",
    "# import soundfile as sf\n",
    "# import librosa\n",
    "\n",
    "# target_classes = ['AS', 'AR', 'MR', 'MS', 'N']\n",
    "\n",
    "# noise_list = []\n",
    "# for k in range(len(train_df)):\n",
    "#     data = train_df.iloc[k]\n",
    "#     # print(data)\n",
    "#     # Get the original patient id and the original labels\n",
    "#     original_patiend_id = data[\"patient_id\"]\n",
    "#     original_labels = data[target_classes].values\n",
    "\n",
    "        \n",
    "#     noise_list_01 = []\n",
    "#     noise_list_05 = []\n",
    "\n",
    "#     #new patient id\n",
    "#     new_patient_id_1 = original_patiend_id + \"_3\"\n",
    "#     new_patient_id_2 = original_patiend_id + \"_4\"\n",
    "\n",
    "#     for i in range(8):\n",
    "#         column_name = f\"recording_{i+1}\"\n",
    "#         # fetch the audio file\n",
    "#         audio_file = data[column_name]\n",
    "#         file_path = train_dir_path + audio_file + \".wav\"\n",
    "#         aud, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "#         # add noise with noise factor 0.01 and 0.05\n",
    "#         noise_audio_01 = add_noise(aud, 0.01)\n",
    "#         noise_audio_05 = add_noise(aud, 0.05)\n",
    "\n",
    "#         new_audio_file_01 = audio_file + \"_noise_01\"\n",
    "#         new_audio_file_05 = audio_file + \"_noise_05\"\n",
    "\n",
    "#         save_location_01 = train_dir_path + new_audio_file_01 + \".wav\"\n",
    "#         save_location_05 = train_dir_path + new_audio_file_05 + \".wav\"\n",
    "\n",
    "#         sf.write(save_location_01, noise_audio_01, sr)\n",
    "#         sf.write(save_location_05, noise_audio_05, sr)\n",
    "\n",
    "#         noise_list_01.append(new_audio_file_01)\n",
    "#         noise_list_05.append(new_audio_file_05)\n",
    "    \n",
    "#     # add the new patient id, original labels and the new audio files to the dataframe\n",
    "#     #concatenate the original labels with the new audio files\n",
    "    \n",
    "#     # convert new_patient_id_1, new_patient_id_2 to a numpy array\n",
    "#     new_patient_id_1 = np.array([new_patient_id_1])\n",
    "#     new_patient_id_2 = np.array([new_patient_id_2])\n",
    "#     new_list = np.concatenate((new_patient_id_1, original_labels, noise_list_01))\n",
    "#     noise_list.append(new_list)\n",
    "#     new_list = np.concatenate((new_patient_id_2, original_labels, noise_list_05))\n",
    "#     noise_list.append(new_list)\n",
    "\n",
    "\n",
    "# # data augmentation using pitch_shift change\n",
    "\n",
    "# # for each patient id, create a new audio file with pitch_shift change and add a new row to the dataframe with the new audio file and patient id as previous patient id + \"i\" where i is 1 or 2\n",
    "\n",
    "# # keep the target columns the same\n",
    "\n",
    "# # pitch_up = 2\n",
    "# # pitch_down = -2\n",
    "\n",
    "# import soundfile as sf\n",
    "# import librosa\n",
    "\n",
    "# target_classes = ['AS', 'AR', 'MR', 'MS', 'N']\n",
    "\n",
    "# pitch_shift_list = []\n",
    "# for k in range(len(train_df)):\n",
    "#     data = train_df.iloc[k]\n",
    "#     # print(data)\n",
    "#     # Get the original patient id and the original labels\n",
    "#     original_patiend_id = data[\"patient_id\"]\n",
    "#     original_labels = data[target_classes].values\n",
    "\n",
    "        \n",
    "#     pitch_up_list = []\n",
    "#     pitch_down_list = []\n",
    "\n",
    "\n",
    "#     #new patient id\n",
    "#     new_patient_id_1 = original_patiend_id + \"_5\"\n",
    "#     new_patient_id_2 = original_patiend_id + \"_6\"\n",
    "\n",
    "#     for i in range(8):\n",
    "#         column_name = f\"recording_{i+1}\"\n",
    "#         # fetch the audio file\n",
    "#         audio_file = data[column_name]\n",
    "#         file_path = train_dir_path + audio_file + \".wav\"\n",
    "#         aud, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "#         # change the pitch_shift of the audio file\n",
    "#         pitch_up_audio = librosa.effects.pitch_shift(aud, sr = sr, n_steps=2)\n",
    "#         pitch_down_audio = librosa.effects.pitch_shift(aud, sr = sr, n_steps=-2)\n",
    "\n",
    "#         new_audio_up = audio_file + \"_pitch_up\"\n",
    "#         new_audio_down = audio_file + \"_pitch_down\"\n",
    "\n",
    "#         save_location_up = train_dir_path + new_audio_up + \".wav\"\n",
    "#         save_location_down = train_dir_path + new_audio_down + \".wav\"\n",
    "\n",
    "#         sf.write(save_location_up, pitch_up_audio, sr)\n",
    "#         sf.write(save_location_down, pitch_down_audio, sr)\n",
    "\n",
    "#         pitch_up_list.append(new_audio_up)\n",
    "#         pitch_down_list.append(new_audio_down)\n",
    "    \n",
    "#     # add the new patient id, original labels and the new audio files to the dataframe\n",
    "#     #concatenate the original labels with the new audio files\n",
    "    \n",
    "#     # convert new_patient_id_1, new_patient_id_2 to a numpy array\n",
    "#     new_patient_id_1 = np.array([new_patient_id_1])\n",
    "#     new_patient_id_2 = np.array([new_patient_id_2])\n",
    "#     new_list = np.concatenate((new_patient_id_1, original_labels, pitch_up_list))\n",
    "#     pitch_shift_list.append(new_list)\n",
    "#     new_list = np.concatenate((new_patient_id_2, original_labels, pitch_down_list))\n",
    "#     pitch_shift_list.append(new_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:42:50.888799Z",
     "iopub.status.busy": "2024-02-20T08:42:50.888354Z",
     "iopub.status.idle": "2024-02-20T08:42:50.895639Z",
     "shell.execute_reply": "2024-02-20T08:42:50.894141Z",
     "shell.execute_reply.started": "2024-02-20T08:42:50.888769Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm \n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Specific Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:42:50.897986Z",
     "iopub.status.busy": "2024-02-20T08:42:50.897551Z",
     "iopub.status.idle": "2024-02-20T08:42:55.376243Z",
     "shell.execute_reply": "2024-02-20T08:42:55.374829Z",
     "shell.execute_reply.started": "2024-02-20T08:42:50.897958Z"
    }
   },
   "outputs": [],
   "source": [
    "# delete all the files and directories recursively in the current working directory ...\n",
    "\n",
    "!rm -rf *\n",
    "\n",
    "# make directory ...\n",
    "\n",
    "!mkdir /kaggle/working/datasets\n",
    "!mkdir /kaggle/working/datasets/train\n",
    "!mkdir /kaggle/working/datasets/test\n",
    "\n",
    "#  reference original files without duplicating their content ...\n",
    "\n",
    "def all_files_in_folder_symlink(source_dir, target_dir):\n",
    "    files = os.listdir(source_dir)\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        source_file = os.path.join(source_dir, file)\n",
    "        target_file = os.path.join(target_dir, file)\n",
    "        os.symlink(source_file, target_file)\n",
    "# symbolic link function as above ...\n",
    "\n",
    "\n",
    "all_files_in_folder_symlink(\"/kaggle/input/biomed-datathon-bmefest2/train\",\"/kaggle/working/datasets/train\")\n",
    "all_files_in_folder_symlink(\"/kaggle/input/biomed-datathon-bmefest2/test\",\"/kaggle/working/datasets/test\")\n",
    "os.symlink(\"/kaggle/input/biomed-datathon-bmefest2/additional_metadata.csv\", \"/kaggle/working/datasets/additional_metadata.csv\")\n",
    "os.symlink(\"/kaggle/input/biomed-datathon-bmefest2/sample_submission.csv\", \"/kaggle/working/datasets/sample_submission.csv\")\n",
    "os.symlink(\"/kaggle/input/biomed-datathon-bmefest2/test_files.csv\", \"/kaggle/working/datasets/test_files.csv\")\n",
    "os.symlink(\"/kaggle/input/biomed-datathon-bmefest2/train.csv\", \"/kaggle/working/datasets/train.csv\")\n",
    "\n",
    "os.symlink (\"/kaggle/input/biomed-datathon-bmefest2/train/085_sit_Tri6_06.wav\", \"/kaggle/working/datasets/train/085_sit_Tri.wav\")\n",
    "\n",
    "train_dir_path = \"/kaggle/working/datasets/train/\"\n",
    "test_dir_path = \"/kaggle/working/datasets/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:42:55.379699Z",
     "iopub.status.busy": "2024-02-20T08:42:55.379009Z",
     "iopub.status.idle": "2024-02-20T08:42:55.414666Z",
     "shell.execute_reply": "2024-02-20T08:42:55.413486Z",
     "shell.execute_reply.started": "2024-02-20T08:42:55.379655Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dir_path = \"train/\"\n",
    "# test_dir_path = \"test/\"\n",
    "\n",
    "# load the train, test, sample csv [reset]\n",
    "train_df = pd.read_csv(\"/kaggle/working/datasets/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/working/datasets/test_files.csv\")\n",
    "# sample_submit_df = pd.read_csv(\"sample_submission.csv\")\n",
    "# check the additional metadata\n",
    "# metadata = pd.read_csv(\"additional_metadata.csv\")\n",
    "\n",
    "# print the shape\n",
    "print(train_df.info())\n",
    "print(test_df.info())\n",
    "# metadata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:42:55.416985Z",
     "iopub.status.busy": "2024-02-20T08:42:55.416267Z",
     "iopub.status.idle": "2024-02-20T08:43:07.675637Z",
     "shell.execute_reply": "2024-02-20T08:43:07.674404Z",
     "shell.execute_reply.started": "2024-02-20T08:42:55.416941Z"
    }
   },
   "outputs": [],
   "source": [
    "# Librosa (the mother of audio files)\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import a sample audio file\n",
    "audio_file = train_dir_path + \"002_sit_Aor.wav\"\n",
    "aud, sr = librosa.load(audio_file, sr=None)\n",
    "print(f\"shape of the audio file: {aud.shape}\")\n",
    "print(f\"sample rate: {sr}\")\n",
    "\n",
    "# length of the audio file\n",
    "print(f\"length of the audio file: {len(aud)/sr} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation / Cutting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:43:07.679658Z",
     "iopub.status.busy": "2024-02-20T08:43:07.678872Z",
     "iopub.status.idle": "2024-02-20T08:43:07.687974Z",
     "shell.execute_reply": "2024-02-20T08:43:07.686780Z",
     "shell.execute_reply.started": "2024-02-20T08:43:07.679622Z"
    }
   },
   "outputs": [],
   "source": [
    "# each audio file is 20 seconds long\n",
    "# cut each audio file into 4 parts of 5 seconds each\n",
    "# then add those 4 parts to the dataframe, instead of the original audio file\n",
    "\n",
    "# create a function to cut the audio file into 4 parts\n",
    "def segment_audio_files(file, n_segments=4, segment_length=5):\n",
    "    # load the audio file\n",
    "    aud, sr = librosa.load(file, sr=None)\n",
    "    # get the length of the audio file\n",
    "    length = len(aud)\n",
    "    # get the length of each segment\n",
    "    segment_length = sr * segment_length\n",
    "    # get the number of samples per segment\n",
    "    samples_per_segment = length // n_segments\n",
    "    # get the starting point of each segment\n",
    "    start = 0\n",
    "    # get the ending point of each segment\n",
    "    end = samples_per_segment\n",
    "    # create an empty list to store the segments\n",
    "    segments = []\n",
    "    # loop through the audio file and get the segments\n",
    "    for _ in range(n_segments):\n",
    "        segment = aud[start:end]\n",
    "        segments.append(segment)\n",
    "        start = end\n",
    "        end = start + samples_per_segment\n",
    "    return segments\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:43:07.689942Z",
     "iopub.status.busy": "2024-02-20T08:43:07.689556Z",
     "iopub.status.idle": "2024-02-20T08:43:07.704567Z",
     "shell.execute_reply": "2024-02-20T08:43:07.703428Z",
     "shell.execute_reply.started": "2024-02-20T08:43:07.689906Z"
    }
   },
   "outputs": [],
   "source": [
    "# # test the function\n",
    "segments = segment_audio_files(audio_file)\n",
    "# print the length of the segments and sr\n",
    "for segment in segments:\n",
    "    print(f\"length of the segment: {len(segment)/sr} seconds\")\n",
    "    print(f\"sample rate: {sr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:43:07.706504Z",
     "iopub.status.busy": "2024-02-20T08:43:07.706048Z",
     "iopub.status.idle": "2024-02-20T08:43:07.712299Z",
     "shell.execute_reply": "2024-02-20T08:43:07.711195Z",
     "shell.execute_reply.started": "2024-02-20T08:43:07.706466Z"
    }
   },
   "outputs": [],
   "source": [
    "# # plot the original audio file\n",
    "# plt.figure(figsize=(14, 5))\n",
    "# librosa.display.waveshow(aud, sr=sr, color=\"green\")\n",
    "# plt.title(\"Original Audio File\")\n",
    "# # plt.show()\n",
    "\n",
    "# # plot the segments\n",
    "# plt.figure(figsize=(14, 5))\n",
    "# for i, segment in enumerate(segments):\n",
    "#     plt.subplot(4, 1, i+1)\n",
    "#     librosa.display.waveshow(segment, sr=sr, color=\"green\")\n",
    "#     plt.title(f\"Segment {i+1}\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:43:07.714088Z",
     "iopub.status.busy": "2024-02-20T08:43:07.713769Z",
     "iopub.status.idle": "2024-02-20T08:43:14.688464Z",
     "shell.execute_reply": "2024-02-20T08:43:14.687376Z",
     "shell.execute_reply.started": "2024-02-20T08:43:07.714061Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert all train and test audio files into segments\n",
    "record_classes = [\"recording_1\", \"recording_2\", \"recording_3\", \"recording_4\", \"recording_5\", \"recording_6\", \"recording_7\", \"recording_8\"]\n",
    "labels = [\"AS\", \"AR\", \"MR\", \"MS\", \"N\"]\n",
    "\n",
    "# create a new dataframe that has the same headers as the train dataframe\n",
    "new_train_df = pd.DataFrame(columns=train_df.columns)\n",
    "# print(new_train_df)\n",
    "temp = {}\n",
    "\n",
    "# process each row in the train dataframe\n",
    "for i, row in train_df.iterrows():\n",
    "    # extract the labels first \n",
    "    label = train_df.iloc[i][1:6] \n",
    "    # print(label)\n",
    "    # get the audio file from each of the 8 columns\n",
    "    for col in record_classes:\n",
    "        audio_file = train_dir_path + row[col] + \".wav\"\n",
    "        segments = segment_audio_files(audio_file)\n",
    "        # now we have 4 segments all of which has the similar labels\n",
    "        temp[col] = segments\n",
    "    # print(len(temp))\n",
    "    # now we have 8 segments for each row\n",
    "    # we need to add each segment to the new dataframe\n",
    "    for i in range(4):\n",
    "        new_row = row.copy()\n",
    "        for col in record_classes:\n",
    "            new_row[col] = temp[col][i]\n",
    "        new_train_df = new_train_df._append(new_row, ignore_index=True)\n",
    "train_df = new_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:43:14.690016Z",
     "iopub.status.busy": "2024-02-20T08:43:14.689715Z",
     "iopub.status.idle": "2024-02-20T08:43:14.833449Z",
     "shell.execute_reply": "2024-02-20T08:43:14.832318Z",
     "shell.execute_reply.started": "2024-02-20T08:43:14.689991Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:43:14.834997Z",
     "iopub.status.busy": "2024-02-20T08:43:14.834705Z",
     "iopub.status.idle": "2024-02-20T08:43:14.840800Z",
     "shell.execute_reply": "2024-02-20T08:43:14.839299Z",
     "shell.execute_reply.started": "2024-02-20T08:43:14.834973Z"
    }
   },
   "outputs": [],
   "source": [
    "# # do the same for test dataframe\n",
    "# new_test_df = pd.DataFrame(columns=test_df.columns)\n",
    "# temp = {}\n",
    "\n",
    "# # process each row in the test dataframe\n",
    "# for i, row in test_df.iterrows():\n",
    "#     # get the audio file from each of the 8 columns\n",
    "#     for col in record_classes:\n",
    "#         audio_file = test_dir_path + row[col] + \".wav\"\n",
    "#         segments = segment_audio_files(audio_file)\n",
    "#         # now we have 4 segments all of which has the similar labels\n",
    "#         temp[col] = segments\n",
    "#     # now we have 8 segments for each row\n",
    "#     # we need to add each segment to the new dataframe\n",
    "#     for i in range(4):\n",
    "#         new_row = row.copy()\n",
    "#         for col in record_classes:\n",
    "#             new_row[col] = temp[col][i]\n",
    "#         new_test_df = new_test_df._append(new_row, ignore_index=True)\n",
    "# test_df = new_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:43:14.845757Z",
     "iopub.status.busy": "2024-02-20T08:43:14.845285Z",
     "iopub.status.idle": "2024-02-20T08:43:28.092675Z",
     "shell.execute_reply": "2024-02-20T08:43:28.091480Z",
     "shell.execute_reply.started": "2024-02-20T08:43:14.845709Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. zero crossing rate column for all the audio files\n",
    "zero_crossing_rate_list = []\n",
    "# create slot for 8 plots in a single figure\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(8):\n",
    "    column_name = f\"recording_{i+1}\"\n",
    "    new_column_name = f\"zero_crossing_rate_{i+1}\"\n",
    "    zero_crossing_rate = []\n",
    "    for aud in train_df[column_name]:\n",
    "        # file_path = train_dir_path + audio_file + \".wav\"\n",
    "        # aud, sr = librosa.load(file_path, sr=None)\n",
    "        zero_crossing_rate.append(librosa.feature.zero_crossing_rate(np.array(aud), frame_length=1024, hop_length=256).mean())\n",
    "    zero_crossing_rate_list.append(zero_crossing_rate)\n",
    "    train_df[new_column_name] = zero_crossing_rate\n",
    "    # plot the newly added column and put all the plots in a single figure\n",
    "    # keep some gaps between the plots\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.title(new_column_name)\n",
    "    plt.plot(zero_crossing_rate)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "zero_crossing_rate_list = []\n",
    "for i in range(8):\n",
    "    column_name = f\"recording_{i+1}\"\n",
    "    new_column_name = f\"zero_crossing_rate_{i+1}\"\n",
    "    zero_crossing_rate = []\n",
    "    for audio_file in test_df[column_name]:\n",
    "        file_path = test_dir_path + audio_file + \".wav\"\n",
    "        aud, sr = librosa.load(file_path, sr=None)\n",
    "        zero_crossing_rate.append(librosa.feature.zero_crossing_rate(aud, frame_length=1024, hop_length=256).mean())\n",
    "    zero_crossing_rate_list.append(zero_crossing_rate)\n",
    "    test_df[new_column_name] = zero_crossing_rate\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.title(new_column_name)\n",
    "    plt.plot(zero_crossing_rate)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:43:28.094943Z",
     "iopub.status.busy": "2024-02-20T08:43:28.094516Z",
     "iopub.status.idle": "2024-02-20T08:43:33.926535Z",
     "shell.execute_reply": "2024-02-20T08:43:33.925411Z",
     "shell.execute_reply.started": "2024-02-20T08:43:28.094907Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. energy column for all the audio files\n",
    "energy_list = []\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(8):\n",
    "    column_name = f\"recording_{i+1}\"\n",
    "    new_column_name = f\"energy_{i+1}\"\n",
    "    energy = []\n",
    "    for aud in train_df[column_name]:\n",
    "        energy.append((np.sum(aud**2))/len(aud))\n",
    "    energy_list.append(energy)\n",
    "    train_df[new_column_name] = energy\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.title(new_column_name)\n",
    "    plt.plot(energy)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "energy_list = []\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(8):\n",
    "    column_name = f\"recording_{i+1}\"\n",
    "    new_column_name = f\"energy_{i+1}\"\n",
    "    energy = []\n",
    "    for audio_file in test_df[column_name]:\n",
    "        file_path = test_dir_path + audio_file + \".wav\"\n",
    "        aud, sr = librosa.load(file_path, sr=None)\n",
    "        energy.append((np.sum(aud**2))/len(aud))\n",
    "    energy_list.append(energy)\n",
    "    test_df[new_column_name] = energy\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.title(new_column_name)\n",
    "    plt.plot(energy)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:43:33.928925Z",
     "iopub.status.busy": "2024-02-20T08:43:33.928206Z",
     "iopub.status.idle": "2024-02-20T08:43:39.503692Z",
     "shell.execute_reply": "2024-02-20T08:43:39.502855Z",
     "shell.execute_reply.started": "2024-02-20T08:43:33.928883Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3. amplitude for all the audio files\n",
    "amplitude_list = []\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(8):\n",
    "    column_name = f\"recording_{i+1}\"\n",
    "    new_column_name = f\"amplitude_{i+1}\"\n",
    "    amplitude = []\n",
    "    for aud in train_df[column_name]:\n",
    "        amplitude.append(np.max(np.abs(aud)))\n",
    "    amplitude_list.append(amplitude)\n",
    "    train_df[new_column_name] = amplitude\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.title(new_column_name)\n",
    "    plt.plot(amplitude)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "amplitude_list = []\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(8):\n",
    "    column_name = f\"recording_{i+1}\"\n",
    "    new_column_name = f\"amplitude_{i+1}\"\n",
    "    amplitude = []\n",
    "    for audio_file in test_df[column_name]:\n",
    "        file_path = test_dir_path + audio_file + \".wav\"\n",
    "        aud, sr = librosa.load(file_path, sr=None)\n",
    "        amplitude.append(np.max(np.abs(aud)))\n",
    "    amplitude_list.append(amplitude)\n",
    "    test_df[new_column_name] = amplitude\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.title(new_column_name)\n",
    "    plt.plot(amplitude)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:43:39.505922Z",
     "iopub.status.busy": "2024-02-20T08:43:39.505008Z",
     "iopub.status.idle": "2024-02-20T08:43:51.443085Z",
     "shell.execute_reply": "2024-02-20T08:43:51.442113Z",
     "shell.execute_reply.started": "2024-02-20T08:43:39.505887Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4. spectral centroid column for all the audio files\n",
    "spectral_centroid_list = []\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(8):\n",
    "    column_name = f\"recording_{i+1}\"\n",
    "    new_column_name = f\"spectral_centroid_{i+1}\"\n",
    "    spectral_centroid = []\n",
    "    for aud in train_df[column_name]:\n",
    "        # file_path = train_dir_path + audio_file + \".wav\"\n",
    "        # aud, sr = librosa.load(file_path, sr=None)\n",
    "        spectral_centroid.append(librosa.feature.spectral_centroid(y=np.array(aud), sr=sr).mean())\n",
    "    spectral_centroid_list.append(spectral_centroid)\n",
    "    train_df[new_column_name] = spectral_centroid\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.title(new_column_name)\n",
    "    plt.plot(spectral_centroid)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "spectral_centroid_list = []\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(8):\n",
    "    column_name = f\"recording_{i+1}\"\n",
    "    new_column_name = f\"spectral_centroid_{i+1}\"\n",
    "    spectral_centroid = []\n",
    "    for audio_file in test_df[column_name]:\n",
    "        file_path = test_dir_path + audio_file + \".wav\"\n",
    "        aud, sr = librosa.load(file_path, sr=None)\n",
    "        spectral_centroid.append(librosa.feature.spectral_centroid(y=aud, sr=sr).mean())\n",
    "    spectral_centroid_list.append(spectral_centroid)\n",
    "    test_df[new_column_name] = spectral_centroid\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.title(new_column_name)\n",
    "    plt.plot(spectral_centroid)\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:43:51.445035Z",
     "iopub.status.busy": "2024-02-20T08:43:51.444348Z",
     "iopub.status.idle": "2024-02-20T08:44:03.813342Z",
     "shell.execute_reply": "2024-02-20T08:44:03.812477Z",
     "shell.execute_reply.started": "2024-02-20T08:43:51.445000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5. spectral roll-off column for all the audio files\n",
    "spectral_rolloff_list = []\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(8):\n",
    "    column_name = f\"recording_{i+1}\"\n",
    "    new_column_name = f\"spectral_rolloff_{i+1}\"\n",
    "    spectral_rolloff = []\n",
    "    for aud in train_df[column_name]:\n",
    "        # file_path = train_dir_path + audio_file + \".wav\"\n",
    "        # aud, sr = librosa.load(file_path, sr=None)\n",
    "        spectral_rolloff.append(librosa.feature.spectral_rolloff(y=np.array(aud), sr=sr).mean())\n",
    "    spectral_rolloff_list.append(spectral_rolloff)\n",
    "    train_df[new_column_name] = spectral_rolloff\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.title(new_column_name)\n",
    "    plt.plot(spectral_rolloff)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "spectral_rolloff_list = []\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(8):\n",
    "    column_name = f\"recording_{i+1}\"\n",
    "    new_column_name = f\"spectral_rolloff_{i+1}\"\n",
    "    spectral_rolloff = []\n",
    "    for audio_file in test_df[column_name]:\n",
    "        file_path = test_dir_path + audio_file + \".wav\"\n",
    "        aud, sr = librosa.load(file_path, sr=None)\n",
    "        spectral_rolloff.append(librosa.feature.spectral_rolloff(y=aud, sr=sr).mean())\n",
    "    spectral_rolloff_list.append(spectral_rolloff)\n",
    "    test_df[new_column_name] = spectral_rolloff\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.title(new_column_name)\n",
    "    plt.plot(spectral_rolloff)\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:44:03.815268Z",
     "iopub.status.busy": "2024-02-20T08:44:03.814654Z",
     "iopub.status.idle": "2024-02-20T08:44:42.210697Z",
     "shell.execute_reply": "2024-02-20T08:44:42.209645Z",
     "shell.execute_reply.started": "2024-02-20T08:44:03.815235Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6. mel-frequency cepstral coefficients (MFCCs) column for all the audio files\n",
    "mfcc_list = []\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(8):\n",
    "    column_name = f\"recording_{i+1}\"\n",
    "    new_column_name = f\"mfcc_{i+1}\"\n",
    "    mfcc = []\n",
    "    for aud in train_df[column_name]:\n",
    "        # file_path = train_dir_path + audio_file + \".wav\"\n",
    "        # aud, sr = librosa.load(file_path, sr=None)\n",
    "        mfcc.append(librosa.feature.mfcc(y=np.array(aud), sr=sr, n_mfcc=13).mean())\n",
    "    mfcc_list.append(mfcc)\n",
    "    train_df[new_column_name] = mfcc\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.title(new_column_name)\n",
    "    plt.plot(mfcc)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mfcc_list = []\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(8):\n",
    "    column_name = f\"recording_{i+1}\"\n",
    "    new_column_name = f\"mfcc_{i+1}\"\n",
    "    mfcc = []\n",
    "    for audio_file in test_df[column_name]:\n",
    "        file_path = test_dir_path + audio_file + \".wav\"\n",
    "        aud, sr = librosa.load(file_path, sr=None)\n",
    "        mfcc.append(librosa.feature.mfcc(y=aud, sr=sr, n_mfcc=13).mean())\n",
    "    mfcc_list.append(mfcc)\n",
    "    test_df[new_column_name] = mfcc\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.title(new_column_name)\n",
    "    plt.plot(mfcc)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:44:42.212994Z",
     "iopub.status.busy": "2024-02-20T08:44:42.212539Z",
     "iopub.status.idle": "2024-02-20T08:45:20.451179Z",
     "shell.execute_reply": "2024-02-20T08:45:20.448828Z",
     "shell.execute_reply.started": "2024-02-20T08:44:42.212952Z"
    }
   },
   "outputs": [],
   "source": [
    "# 7. chroma feature column for all the audio files\n",
    "chroma_stft_list = []\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(8):\n",
    "    column_name = f\"recording_{i+1}\"\n",
    "    new_column_name = f\"chroma_stft_{i+1}\"\n",
    "    chroma_stft = []\n",
    "    for aud in train_df[column_name]:\n",
    "        # file_path = train_dir_path + audio_file + \".wav\"\n",
    "        # aud, sr = librosa.load(file_path, sr=None)\n",
    "        chroma_stft.append(librosa.feature.chroma_stft(y=np.array(aud), sr=sr).mean())\n",
    "    chroma_stft_list.append(chroma_stft)\n",
    "    train_df[new_column_name] = chroma_stft\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.title(new_column_name)\n",
    "    plt.plot(chroma_stft)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "chroma_stft_list = []\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(8):\n",
    "    column_name = f\"recording_{i+1}\"\n",
    "    new_column_name = f\"chroma_stft_{i+1}\"\n",
    "    chroma_stft = []\n",
    "    for audio_file in test_df[column_name]:\n",
    "        file_path = test_dir_path + audio_file + \".wav\"\n",
    "        aud, sr = librosa.load(file_path, sr=None)\n",
    "        chroma_stft.append(librosa.feature.chroma_stft(y=aud, sr=sr).mean())\n",
    "    chroma_stft_list.append(chroma_stft)\n",
    "    test_df[new_column_name] = chroma_stft\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.title(new_column_name)\n",
    "    plt.plot(chroma_stft)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:45:20.453358Z",
     "iopub.status.busy": "2024-02-20T08:45:20.452959Z",
     "iopub.status.idle": "2024-02-20T08:45:20.465899Z",
     "shell.execute_reply": "2024-02-20T08:45:20.464814Z",
     "shell.execute_reply.started": "2024-02-20T08:45:20.453320Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop all the recording name columns from the train and test data\n",
    "train_df.drop(columns=[f\"recording_{i+1}\" for i in range(8)], inplace=True)\n",
    "test_df.drop(columns=[f\"recording_{i+1}\" for i in range(8)], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:45:20.469690Z",
     "iopub.status.busy": "2024-02-20T08:45:20.467670Z",
     "iopub.status.idle": "2024-02-20T08:45:20.484431Z",
     "shell.execute_reply": "2024-02-20T08:45:20.483266Z",
     "shell.execute_reply.started": "2024-02-20T08:45:20.469650Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the train data into features and target\n",
    "train_ids = train_df[\"patient_id\"]\n",
    "test_ids = test_df[\"patient_id\"]\n",
    "y = train_df[[\"AS\", \"AR\", \"MR\", \"MS\", \"N\"]]\n",
    "train_df = train_df.drop(columns=[\"patient_id\", \"AS\", \"AR\", \"MR\", \"MS\", \"N\"])\n",
    "X = train_df\n",
    "test_df = test_df.drop(columns=[\"patient_id\"])\n",
    "Y = test_df\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:45:20.486704Z",
     "iopub.status.busy": "2024-02-20T08:45:20.486279Z",
     "iopub.status.idle": "2024-02-20T08:45:20.494909Z",
     "shell.execute_reply": "2024-02-20T08:45:20.493885Z",
     "shell.execute_reply.started": "2024-02-20T08:45:20.486668Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the train and test data to a temporary csv file\n",
    "filename = \"segmented_zero_centroid_rolloff_mfcc_chroma.csv\"\n",
    "train_filename = \"segmented_zero_energy_amplitude_centroid_rolloff_mfcc_chroma_train.csv\"\n",
    "test_filename = \"segmented_zero_energy_amplitude_centroid_rolloff_mfcc_chroma_test.csv\"\n",
    "# X.to_csv(train_filename, index=False)\n",
    "# Y.to_csv(test_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:45:42.752058Z",
     "iopub.status.busy": "2024-02-20T08:45:42.751630Z",
     "iopub.status.idle": "2024-02-20T08:45:42.758132Z",
     "shell.execute_reply": "2024-02-20T08:45:42.756607Z",
     "shell.execute_reply.started": "2024-02-20T08:45:42.752028Z"
    }
   },
   "outputs": [],
   "source": [
    "# # load the train and test data\n",
    "# X = pd.read_csv(train_filename)\n",
    "# Y = pd.read_csv(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:46:41.338866Z",
     "iopub.status.busy": "2024-02-20T08:46:41.338342Z",
     "iopub.status.idle": "2024-02-20T08:46:41.382829Z",
     "shell.execute_reply": "2024-02-20T08:46:41.381103Z",
     "shell.execute_reply.started": "2024-02-20T08:46:41.338824Z"
    }
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:47:19.868666Z",
     "iopub.status.busy": "2024-02-20T08:47:19.867484Z",
     "iopub.status.idle": "2024-02-20T08:47:19.883031Z",
     "shell.execute_reply": "2024-02-20T08:47:19.881691Z",
     "shell.execute_reply.started": "2024-02-20T08:47:19.868625Z"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:47:26.438899Z",
     "iopub.status.busy": "2024-02-20T08:47:26.438431Z",
     "iopub.status.idle": "2024-02-20T08:47:26.444797Z",
     "shell.execute_reply": "2024-02-20T08:47:26.443474Z",
     "shell.execute_reply.started": "2024-02-20T08:47:26.438865Z"
    }
   },
   "outputs": [],
   "source": [
    "# make the y values into integer\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:47:35.996634Z",
     "iopub.status.busy": "2024-02-20T08:47:35.996180Z",
     "iopub.status.idle": "2024-02-20T08:47:36.002154Z",
     "shell.execute_reply": "2024-02-20T08:47:36.000848Z",
     "shell.execute_reply.started": "2024-02-20T08:47:35.996599Z"
    }
   },
   "outputs": [],
   "source": [
    "# # plot the target label imbalance\n",
    "# plt.figure(figsize=(15, 10))\n",
    "\n",
    "# # check for target label imbalance\n",
    "# for cls in y.columns:\n",
    "#     print(f\"{cls}: {y[cls].value_counts()}\")\n",
    "#     plt.subplot(2, 3, list(y.columns).index(cls)+1)\n",
    "#     sns.countplot(x=cls, data=y)\n",
    "#     plt.title(cls)\n",
    "#     plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:47:36.399769Z",
     "iopub.status.busy": "2024-02-20T08:47:36.399034Z",
     "iopub.status.idle": "2024-02-20T08:47:36.405063Z",
     "shell.execute_reply": "2024-02-20T08:47:36.403951Z",
     "shell.execute_reply.started": "2024-02-20T08:47:36.399735Z"
    }
   },
   "outputs": [],
   "source": [
    "# # normalize the data\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# Y = scaler.transform(Y)\n",
    "\n",
    "\n",
    "# # principal component analysis and dimensionality reduction\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# X_pca = pca.fit_transform(X)\n",
    "# Y_pca = pca.transform(Y)\n",
    "\n",
    "# # plot the pca\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y[\"AS\"], cmap=\"viridis\", label=\"AS\")\n",
    "# plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y[\"AR\"], cmap=\"viridis\", label=\"AR\")\n",
    "# plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y[\"MR\"], cmap=\"viridis\", label=\"MR\")\n",
    "# plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y[\"MS\"], cmap=\"viridis\", label=\"MS\")\n",
    "# plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y[\"N\"], cmap=\"viridis\", label=\"N\")\n",
    "# plt.xlabel(\"Principal Component 1\")\n",
    "# plt.ylabel(\"Principal Component 2\")\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier With Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:47:42.428970Z",
     "iopub.status.busy": "2024-02-20T08:47:42.428566Z",
     "iopub.status.idle": "2024-02-20T08:47:56.055753Z",
     "shell.execute_reply": "2024-02-20T08:47:56.054462Z",
     "shell.execute_reply.started": "2024-02-20T08:47:42.428942Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "Y = scaler.transform(Y)\n",
    "\n",
    "\n",
    "# use a leave-one-out cross-validation\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import f1_score\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# create a decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# create a list to store the predictions\n",
    "accuracies = []\n",
    "# iterate over the leave-one-out cross-validation and plot the accuracy\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    print(f\"true label: {y_test.values[0]}\")\n",
    "    print(f\"predicted label: {y_pred[0]}\")\n",
    "    # calculate the f1 score\n",
    "    accuracies.append(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    print(f\"f1 score: {f1_score(y_test, y_pred, average='macro')}\")\n",
    "print(f\"mean f1 score: {np.mean(accuracies)}\")\n",
    "# plot the f1 scores\n",
    "plt.plot(accuracies)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"F1 Score vs Iteration\")\n",
    "\n",
    "# fit the model on the entire train data\n",
    "dt.fit(X, y)\n",
    "# make predictions on the test data\n",
    "test_preds = dt.predict(Y)\n",
    "# create a submission dataframe\n",
    "submission = pd.DataFrame(test_preds, columns=[\"AS\", \"AR\", \"MR\", \"MS\", \"N\"])\n",
    "submission[\"patient_id\"] = test_ids\n",
    "submission = submission[[\"patient_id\", \"AS\", \"AR\", \"MR\", \"MS\", \"N\"]]\n",
    "# check the submission\n",
    "print(submission.head())\n",
    "\n",
    "\n",
    "# feature importance of the decision tree\n",
    "feature_importance = dt.feature_importances_\n",
    "# print all the feature importance and their corresponding column names\n",
    "print(feature_importance)\n",
    "print(train_df.columns)\n",
    "\n",
    "column_names = train_df.columns\n",
    "\n",
    "# plot the feature importance\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.barplot(x=feature_importance, y=column_names)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()\n",
    "\n",
    "# select the top 35 features from the sorted values of the feature importance\n",
    "top_35_features = column_names[np.argsort(feature_importance)[::-1][:35]]\n",
    "# print the top 35 features and their importance values\n",
    "print(top_35_features)\n",
    "print(feature_importance[np.argsort(feature_importance)[::-1][:35]])\n",
    "\n",
    "# only keep these features in the train and test data\n",
    "X = train_df[top_35_features]\n",
    "Y = test_df[top_35_features]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "Y = scaler.transform(Y)\n",
    "\n",
    "# use a leave-one-out cross-validation\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import f1_score\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# create a decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# create a list to store the predictions\n",
    "accuracies = []\n",
    "# iterate over the leave-one-out cross-validation and plot the accuracy\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    print(f\"true label: {y_test.values[0]}\")\n",
    "    print(f\"predicted label: {y_pred[0]}\")\n",
    "    # calculate the f1 score\n",
    "    accuracies.append(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    print(f\"f1 score: {f1_score(y_test, y_pred, average='macro')}\")\n",
    "print(f\"mean f1 score: {np.mean(accuracies)}\")\n",
    "# plot the f1 scores\n",
    "plt.plot(accuracies)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"F1 Score vs Iteration\")\n",
    "\n",
    "# fit the model on the entire train data\n",
    "dt.fit(X, y)\n",
    "# make predictions on the test data\n",
    "test_preds = dt.predict(Y)\n",
    "# create a submission dataframe\n",
    "submission = pd.DataFrame(test_preds, columns=[\"AS\", \"AR\", \"MR\", \"MS\", \"N\"])\n",
    "submission[\"patient_id\"] = test_ids\n",
    "submission = submission[[\"patient_id\", \"AS\", \"AR\", \"MR\", \"MS\", \"N\"]]\n",
    "# check the submission\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:48:15.974662Z",
     "iopub.status.busy": "2024-02-20T08:48:15.974169Z",
     "iopub.status.idle": "2024-02-20T08:48:15.982759Z",
     "shell.execute_reply": "2024-02-20T08:48:15.981617Z",
     "shell.execute_reply.started": "2024-02-20T08:48:15.974626Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_dt_35_segmented_7_feat.csv\", index=False) # 0.3853"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-20T08:45:21.170839Z",
     "iopub.status.idle": "2024-02-20T08:45:21.171374Z",
     "shell.execute_reply": "2024-02-20T08:45:21.171123Z",
     "shell.execute_reply.started": "2024-02-20T08:45:21.171100Z"
    }
   },
   "outputs": [],
   "source": [
    "# # use a leave-one-out cross-validation\n",
    "# from sklearn.model_selection import LeaveOneOut\n",
    "# from sklearn.metrics import f1_score\n",
    "# loo = LeaveOneOut()\n",
    "\n",
    "# # normalize the data\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# Y = scaler.transform(Y)\n",
    "\n",
    "# # try xtreme gradient boosting\n",
    "# from xgboost import XGBClassifier\n",
    "# xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# # create a list to store the predictions\n",
    "# accuracies = []\n",
    "# # iterate over the leave-one-out cross-validation and plot the accuracy\n",
    "# for train_index, test_index in loo.split(X):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#     xgb.fit(X_train, y_train)\n",
    "#     y_pred = xgb.predict(X_test)\n",
    "#     print(f\"true label: {y_test.values[0]}\")\n",
    "#     print(f\"predicted label: {y_pred[0]}\")\n",
    "#     # calculate the f1 score\n",
    "#     accuracies.append(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "#     print(f\"f1 score: {f1_score(y_test, y_pred, average='macro')}\")\n",
    "\n",
    "# print(f\"mean f1 score: {np.mean(accuracies)}\")\n",
    "# # plot the f1 scores\n",
    "# plt.plot(accuracies)\n",
    "# plt.xlabel(\"Iteration\")\n",
    "# plt.ylabel(\"F1 Score\")\n",
    "# plt.title(\"F1 Score vs Iteration\")\n",
    "# plt.show()\n",
    "\n",
    "# # feature importance of the xgboot classifier\n",
    "# feature_importance = xgb.feature_importances_\n",
    "# # print all the feature importance and their corresponding column names\n",
    "# print(feature_importance)\n",
    "# print(train_df.columns)\n",
    "\n",
    "# column_names = train_df.columns\n",
    "\n",
    "# # plot the feature importance\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# sns.barplot(x=feature_importance, y=column_names)\n",
    "# plt.title(\"Feature Importance\")\n",
    "\n",
    "# # select the top 30 features from the sorted values of the feature importance\n",
    "# top_30_features = column_names[np.argsort(feature_importance)[::-1][:30]]\n",
    "# # print the top 30 features and their importance values\n",
    "# print(top_30_features)\n",
    "# print(feature_importance[np.argsort(feature_importance)[::-1][:30]])\n",
    "\n",
    "# # only keep these features in the train and test data\n",
    "# X = train_df[top_30_features]\n",
    "# Y = test_df[top_30_features]\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# Y = scaler.transform(Y)\n",
    "\n",
    "# xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# # use a leave-one-out cross-validation\n",
    "# from sklearn.model_selection import LeaveOneOut\n",
    "# from sklearn.metrics import f1_score\n",
    "# loo = LeaveOneOut()\n",
    "\n",
    "# # create a list to store the predictions\n",
    "# accuracies = []\n",
    "# # iterate over the leave-one-out cross-validation and plot the accuracy\n",
    "# for train_index, test_index in loo.split(X):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#     xgb.fit(X_train, y_train)\n",
    "#     y_pred = xgb.predict(X_test)\n",
    "#     print(f\"true label: {y_test.values[0]}\")\n",
    "#     print(f\"predicted label: {y_pred[0]}\")\n",
    "#     # calculate the f1 score\n",
    "#     accuracies.append(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "#     print(f\"f1 score: {f1_score(y_test, y_pred, average='macro')}\")\n",
    "\n",
    "# print(f\"mean f1 score: {np.mean(accuracies)}\")\n",
    "# # plot the f1 scores\n",
    "# plt.plot(accuracies)\n",
    "# plt.xlabel(\"Iteration\")\n",
    "# plt.ylabel(\"F1 Score\")\n",
    "# plt.title(\"F1 Score vs Iteration\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-20T08:45:21.173987Z",
     "iopub.status.idle": "2024-02-20T08:45:21.174612Z",
     "shell.execute_reply": "2024-02-20T08:45:21.174328Z",
     "shell.execute_reply.started": "2024-02-20T08:45:21.174302Z"
    }
   },
   "outputs": [],
   "source": [
    "# # fit the model on the entire train data\n",
    "# xgb.fit(X, y)\n",
    "# # make predictions on the test data\n",
    "# test_preds = xgb.predict(Y)\n",
    "# # create a submission dataframe\n",
    "# submission = pd.DataFrame(test_preds, columns=[\"AS\", \"AR\", \"MR\", \"MS\", \"N\"])\n",
    "# submission[\"patient_id\"] = test_ids\n",
    "# submission = submission[[\"patient_id\", \"AS\", \"AR\", \"MR\", \"MS\", \"N\"]]\n",
    "# # check the submission\n",
    "# print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-20T08:45:21.175928Z",
     "iopub.status.idle": "2024-02-20T08:45:21.176821Z",
     "shell.execute_reply": "2024-02-20T08:45:21.176556Z",
     "shell.execute_reply.started": "2024-02-20T08:45:21.176533Z"
    }
   },
   "outputs": [],
   "source": [
    "# submission.to_csv(\"submission_xgb_30_segmented_7_feat.csv\", index=False) # 0.3984"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-20T08:45:21.178783Z",
     "iopub.status.idle": "2024-02-20T08:45:21.179303Z",
     "shell.execute_reply": "2024-02-20T08:45:21.179054Z",
     "shell.execute_reply.started": "2024-02-20T08:45:21.179031Z"
    }
   },
   "outputs": [],
   "source": [
    "# # try random forest\n",
    "\n",
    "# # normalize the data\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import f1_score\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# Y = scaler.transform(Y)\n",
    "\n",
    "# rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "# # use a leave-one-out cross-validation\n",
    "# from sklearn.model_selection import LeaveOneOut\n",
    "# loo = LeaveOneOut()\n",
    "\n",
    "# # create a list to store the predictions\n",
    "# accuracies = []\n",
    "# # iterate over the leave-one-out cross-validation and plot the accuracy\n",
    "# for train_index, test_index in loo.split(X):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#     rf.fit(X_train, y_train)\n",
    "#     y_pred = rf.predict(X_test)\n",
    "#     print(f\"true label: {y_test.values[0]}\")\n",
    "#     print(f\"predicted label: {y_pred[0]}\")\n",
    "#     # calculate the f1 score\n",
    "#     accuracies.append(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "#     print(f\"f1 score: {f1_score(y_test, y_pred, average='macro')}\")\n",
    "\n",
    "# print(f\"mean f1 score: {np.mean(accuracies)}\")\n",
    "# # plot the f1 scores\n",
    "# plt.plot(accuracies)\n",
    "# plt.xlabel(\"Iteration\")\n",
    "# plt.ylabel(\"F1 Score\")\n",
    "# plt.title(\"F1 Score vs Iteration\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-20T08:45:21.181017Z",
     "iopub.status.idle": "2024-02-20T08:45:21.181548Z",
     "shell.execute_reply": "2024-02-20T08:45:21.181286Z",
     "shell.execute_reply.started": "2024-02-20T08:45:21.181264Z"
    }
   },
   "outputs": [],
   "source": [
    "# # fit the model on the entire train data\n",
    "# rf.fit(X, y)\n",
    "# # make predictions on the test data\n",
    "# test_preds = rf.predict(Y)\n",
    "# # create a submission dataframe\n",
    "# submission = pd.DataFrame(test_preds, columns=[\"AS\", \"AR\", \"MR\", \"MS\", \"N\"])\n",
    "# submission[\"patient_id\"] = test_ids\n",
    "# submission = submission[[\"patient_id\", \"AS\", \"AR\", \"MR\", \"MS\", \"N\"]]\n",
    "# # check the submission\n",
    "# print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-20T08:45:21.183346Z",
     "iopub.status.idle": "2024-02-20T08:45:21.184248Z",
     "shell.execute_reply": "2024-02-20T08:45:21.183984Z",
     "shell.execute_reply.started": "2024-02-20T08:45:21.183958Z"
    }
   },
   "outputs": [],
   "source": [
    "# # save the submission\n",
    "# submission.to_csv(\"submission_rf_7_feat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-20T08:45:21.185960Z",
     "iopub.status.idle": "2024-02-20T08:45:21.186496Z",
     "shell.execute_reply": "2024-02-20T08:45:21.186231Z",
     "shell.execute_reply.started": "2024-02-20T08:45:21.186208Z"
    }
   },
   "outputs": [],
   "source": [
    "# # apply complex multi-layer perceptron\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import LeaveOneOut\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # normalize the data\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# Y = scaler.transform(Y)\n",
    "\n",
    "# # create a multi-layer perceptron classifier\n",
    "# mlp = MLPClassifier(random_state=42, max_iter=100000)\n",
    "\n",
    "# # use a leave-one-out cross-validation\n",
    "# loo = LeaveOneOut()\n",
    "\n",
    "# # create a list to store the predictions\n",
    "# accuracies = []\n",
    "# # iterate over the leave-one-out cross-validation and plot the accuracy\n",
    "\n",
    "# for train_index, test_index in loo.split(X):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#     mlp.fit(X_train, y_train)\n",
    "#     y_pred = mlp.predict(X_test)\n",
    "#     print(f\"true label: {y_test.values[0]}\")\n",
    "#     print(f\"predicted label: {y_pred[0]}\")\n",
    "#     # calculate the f1 score\n",
    "#     accuracies.append(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "#     print(f\"f1 score: {f1_score(y_test, y_pred, average='macro')}\")\n",
    "\n",
    "# print(f\"mean f1 score: {np.mean(accuracies)}\")\n",
    "# # plot the f1 scores\n",
    "# plt.plot(accuracies)\n",
    "# plt.xlabel(\"Iteration\")\n",
    "# plt.ylabel(\"F1 Score\")\n",
    "# plt.title(\"F1 Score vs Iteration\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-20T08:45:21.188460Z",
     "iopub.status.idle": "2024-02-20T08:45:21.188984Z",
     "shell.execute_reply": "2024-02-20T08:45:21.188736Z",
     "shell.execute_reply.started": "2024-02-20T08:45:21.188713Z"
    }
   },
   "outputs": [],
   "source": [
    "# # fit the model on the entire train data\n",
    "# mlp.fit(X, y)\n",
    "# # make predictions on the test data\n",
    "# test_preds = mlp.predict(Y)\n",
    "# # create a submission dataframe\n",
    "# submission = pd.DataFrame(test_preds, columns=[\"AS\", \"AR\", \"MR\", \"MS\", \"N\"])\n",
    "# submission[\"patient_id\"] = test_ids\n",
    "# submission = submission[[\"patient_id\", \"AS\", \"AR\", \"MR\", \"MS\", \"N\"]]\n",
    "# # check the submission\n",
    "# print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-20T08:45:21.191636Z",
     "iopub.status.idle": "2024-02-20T08:45:21.192156Z",
     "shell.execute_reply": "2024-02-20T08:45:21.191912Z",
     "shell.execute_reply.started": "2024-02-20T08:45:21.191889Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the submission\n",
    "# submission.to_csv(\"submission_mlp_7_feat.csv\", index=False) # 0.3984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-20T08:45:21.194189Z",
     "iopub.status.idle": "2024-02-20T08:45:21.194741Z",
     "shell.execute_reply": "2024-02-20T08:45:21.194478Z",
     "shell.execute_reply.started": "2024-02-20T08:45:21.194456Z"
    }
   },
   "outputs": [],
   "source": [
    "# # handle the data imbalance using MLSMOTE for multi label classification\n",
    "# from collections import Counter\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "# # check the distribution of the target classes\n",
    "# print(Counter(y[\"AS\"]))\n",
    "# print(Counter(y[\"AR\"]))\n",
    "# print(Counter(y[\"MR\"]))\n",
    "# print(Counter(y[\"MS\"]))\n",
    "# print(Counter(y[\"N\"]))\n",
    "\n",
    "# X_trains = []\n",
    "# y_trains = []\n",
    "\n",
    "# # X -> train features, y -> train target, Y -> test features\n",
    "\n",
    "# for cls in target_classes:\n",
    "#     smote = SMOTENC(random_state=42, categorical_features=[0, 1, 2, 3, 4])\n",
    "#     X_train_resampled, y_train_resampled = smote.fit_resample(X, y[cls])\n",
    "#     print(f\"resampled shape for {cls}: {X_train_resampled.shape}\")\n",
    "#     print(f\"resampled target shape for {cls}: {y_train_resampled.shape}\")\n",
    "#     X_trains.append(X_train_resampled)\n",
    "#     y_trains.append(y_train_resampled)\n",
    "\n",
    "\n",
    "# # Now X_train_resampled and y_train_resampled contain the oversampled data for each label\n",
    "\n",
    "# # check the distribution of the target classes\n",
    "# print(Counter(y_trains[0]))\n",
    "# print(Counter(y_trains[1]))\n",
    "# print(Counter(y_trains[2]))\n",
    "# print(Counter(y_trains[3]))\n",
    "# print(Counter(y_trains[4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-20T08:45:21.196751Z",
     "iopub.status.idle": "2024-02-20T08:45:21.197263Z",
     "shell.execute_reply": "2024-02-20T08:45:21.197021Z",
     "shell.execute_reply.started": "2024-02-20T08:45:21.196999Z"
    }
   },
   "outputs": [],
   "source": [
    "# # concatanate the train features and train labels csv into one\n",
    "# new_csv = pd.concat([X, y], axis=1)\n",
    "# # save the new csv\n",
    "# new_csv.to_csv(\"train_features_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:54:01.318070Z",
     "iopub.status.busy": "2024-02-20T08:54:01.317782Z",
     "iopub.status.idle": "2024-02-20T08:55:07.733554Z",
     "shell.execute_reply": "2024-02-20T08:55:07.732562Z",
     "shell.execute_reply.started": "2024-02-20T08:54:01.318045Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install datasets[audio]\n",
    "! pip -q install accelerate -U\n",
    "! pip -q install librosa==0.9.2\n",
    "! pip -q install numpy==1.23.5\n",
    "! pip -q install datasets==2.15\n",
    "from datasets import Dataset, Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:55:07.735960Z",
     "iopub.status.busy": "2024-02-20T08:55:07.735392Z",
     "iopub.status.idle": "2024-02-20T08:55:07.740614Z",
     "shell.execute_reply": "2024-02-20T08:55:07.739613Z",
     "shell.execute_reply.started": "2024-02-20T08:55:07.735933Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Specific Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:55:07.741841Z",
     "iopub.status.busy": "2024-02-20T08:55:07.741570Z",
     "iopub.status.idle": "2024-02-20T08:55:11.845000Z",
     "shell.execute_reply": "2024-02-20T08:55:11.843756Z",
     "shell.execute_reply.started": "2024-02-20T08:55:07.741809Z"
    }
   },
   "outputs": [],
   "source": [
    "# delete all the files and directories recursively in the current working directory ...\n",
    "\n",
    "!rm -rf *\n",
    "\n",
    "# make directory ...\n",
    "\n",
    "!mkdir /kaggle/working/datasets\n",
    "!mkdir /kaggle/working/datasets/train\n",
    "!mkdir /kaggle/working/datasets/test\n",
    "\n",
    "#  reference original files without duplicating their content ...\n",
    "\n",
    "def all_files_in_folder_symlink(source_dir, target_dir):\n",
    "    files = os.listdir(source_dir)\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        source_file = os.path.join(source_dir, file)\n",
    "        target_file = os.path.join(target_dir, file)\n",
    "        os.symlink(source_file, target_file)\n",
    "# symbolic link function as above ...\n",
    "\n",
    "\n",
    "all_files_in_folder_symlink(\"/kaggle/input/biomed-datathon-bmefest2/train\",\"/kaggle/working/datasets/train\")\n",
    "all_files_in_folder_symlink(\"/kaggle/input/biomed-datathon-bmefest2/test\",\"/kaggle/working/datasets/test\")\n",
    "os.symlink(\"/kaggle/input/biomed-datathon-bmefest2/additional_metadata.csv\", \"/kaggle/working/datasets/additional_metadata.csv\")\n",
    "os.symlink(\"/kaggle/input/biomed-datathon-bmefest2/sample_submission.csv\", \"/kaggle/working/datasets/sample_submission.csv\")\n",
    "os.symlink(\"/kaggle/input/biomed-datathon-bmefest2/test_files.csv\", \"/kaggle/working/datasets/test_files.csv\")\n",
    "os.symlink(\"/kaggle/input/biomed-datathon-bmefest2/train.csv\", \"/kaggle/working/datasets/train.csv\")\n",
    "\n",
    "os.symlink (\"/kaggle/input/biomed-datathon-bmefest2/train/085_sit_Tri6_06.wav\", \"/kaggle/working/datasets/train/085_sit_Tri.wav\")\n",
    "\n",
    "train_dir_path = \"/kaggle/working/datasets/train\"\n",
    "test_dir_path = \"/kaggle/working/datasets/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:55:11.848694Z",
     "iopub.status.busy": "2024-02-20T08:55:11.848291Z",
     "iopub.status.idle": "2024-02-20T08:55:11.852845Z",
     "shell.execute_reply": "2024-02-20T08:55:11.851866Z",
     "shell.execute_reply.started": "2024-02-20T08:55:11.848665Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dir_path = \"train\"\n",
    "# test_dir_path = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:55:11.854448Z",
     "iopub.status.busy": "2024-02-20T08:55:11.854044Z",
     "iopub.status.idle": "2024-02-20T08:55:12.814482Z",
     "shell.execute_reply": "2024-02-20T08:55:12.813550Z",
     "shell.execute_reply.started": "2024-02-20T08:55:11.854417Z"
    }
   },
   "outputs": [],
   "source": [
    "! tree -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:55:12.816139Z",
     "iopub.status.busy": "2024-02-20T08:55:12.815822Z",
     "iopub.status.idle": "2024-02-20T08:55:12.868653Z",
     "shell.execute_reply": "2024-02-20T08:55:12.867934Z",
     "shell.execute_reply.started": "2024-02-20T08:55:12.816110Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = Dataset.from_csv(\"/kaggle/working/datasets/train.csv\")\n",
    "data = pd.read_csv(\"/kaggle/working/datasets/train.csv\")\n",
    "# data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, valid_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "train_data = Dataset.from_pandas(train_data)\n",
    "valid_data = Dataset.from_pandas(valid_data)\n",
    "\n",
    "test_data = pd.read_csv(\"/kaggle/working/datasets/test_files.csv\")\n",
    "# test_data = pd.read_csv(\"test_files.csv\")\n",
    "test_data = Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Path to Audio Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:55:12.869864Z",
     "iopub.status.busy": "2024-02-20T08:55:12.869583Z",
     "iopub.status.idle": "2024-02-20T08:55:12.875718Z",
     "shell.execute_reply": "2024-02-20T08:55:12.874790Z",
     "shell.execute_reply.started": "2024-02-20T08:55:12.869816Z"
    }
   },
   "outputs": [],
   "source": [
    "def from_train_path_to_audio(path):\n",
    "    path = str(train_dir_path) + \"/\" + path + \".wav\"\n",
    "    aud, sr = librosa.load(path, sr=None)\n",
    "    return dict({\"array\": aud, \"sampling_rate\": sr})\n",
    "\n",
    "def from_test_path_to_audio(path):\n",
    "    path = str(test_dir_path) + \"/\" + path + \".wav\"\n",
    "    aud, sr = librosa.load(path, sr=None)\n",
    "    return dict({\"array\": aud, \"sampling_rate\": sr})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:55:12.877114Z",
     "iopub.status.busy": "2024-02-20T08:55:12.876841Z",
     "iopub.status.idle": "2024-02-20T08:55:28.105797Z",
     "shell.execute_reply": "2024-02-20T08:55:28.104814Z",
     "shell.execute_reply.started": "2024-02-20T08:55:12.877080Z"
    }
   },
   "outputs": [],
   "source": [
    "recording_columns = [\"recording_1\", \"recording_2\", \"recording_3\", \"recording_4\", \"recording_5\", \"recording_6\", \"recording_7\", \"recording_8\"]\n",
    "labels = [\"AS\", \"AR\", \"MR\", \"MS\", \"N\"]\n",
    "\n",
    "# for each recording column, replace the recording column element path with the audio object using the from_train_path_to_audio function and create a new dataset\n",
    "for recording_column in recording_columns:\n",
    "    train_data = train_data.map(lambda x: {recording_column: from_train_path_to_audio(x[recording_column])}, remove_columns=[recording_column])\n",
    "\n",
    "# do the same for valid data\n",
    "for recording_column in recording_columns:\n",
    "    valid_data = valid_data.map(lambda x: {recording_column: from_train_path_to_audio(x[recording_column])}, remove_columns=[recording_column])\n",
    "\n",
    "for recording_column in recording_columns:\n",
    "    test_data = test_data.map(lambda x: {recording_column: from_test_path_to_audio(x[recording_column])}, remove_columns=[recording_column])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling to 16KHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:55:28.107546Z",
     "iopub.status.busy": "2024-02-20T08:55:28.107180Z",
     "iopub.status.idle": "2024-02-20T08:56:23.037716Z",
     "shell.execute_reply": "2024-02-20T08:56:23.036687Z",
     "shell.execute_reply.started": "2024-02-20T08:55:28.107513Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to 16kHz\n",
    "for recording_column in recording_columns:\n",
    "    train_data = train_data.cast_column(recording_column, Audio(sampling_rate=16000))\n",
    "train_data[0]\n",
    "\n",
    "# same for valid data\n",
    "for recording_column in recording_columns:\n",
    "    valid_data = valid_data.cast_column(recording_column, Audio(sampling_rate=16000))\n",
    "valid_data[0]\n",
    "\n",
    "# same for valid data\n",
    "for recording_column in recording_columns:\n",
    "    test_data = test_data.cast_column(recording_column, Audio(sampling_rate=16000))\n",
    "test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Recording Wise Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:56:23.042151Z",
     "iopub.status.busy": "2024-02-20T08:56:23.041861Z",
     "iopub.status.idle": "2024-02-20T08:59:07.108627Z",
     "shell.execute_reply": "2024-02-20T08:59:07.107723Z",
     "shell.execute_reply.started": "2024-02-20T08:56:23.042127Z"
    }
   },
   "outputs": [],
   "source": [
    "# there are 8 recordings for each row, we will create 8 different datasets for each recording, and drop the other recordings\n",
    "train_datasets = []\n",
    "for recording_column in recording_columns:\n",
    "    train_dataset = train_data.map(lambda x: {\"audio\": x[recording_column]}, remove_columns=recording_columns)\n",
    "    train_datasets.append(train_dataset)\n",
    "train_datasets[0]\n",
    "\n",
    "# same for valid data\n",
    "valid_datasets = []\n",
    "for recording_column in recording_columns:\n",
    "    valid_dataset = valid_data.map(lambda x: {\"audio\": x[recording_column]}, remove_columns=recording_columns)\n",
    "    valid_datasets.append(valid_dataset)\n",
    "valid_datasets[0]\n",
    "\n",
    "# same for valid data\n",
    "test_datasets = []\n",
    "for recording_column in recording_columns:\n",
    "    test_dataset = test_data.map(lambda x: {\"audio\": x[recording_column]}, remove_columns=recording_columns)\n",
    "    test_datasets.append(test_dataset)\n",
    "test_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:59:07.109983Z",
     "iopub.status.busy": "2024-02-20T08:59:07.109732Z",
     "iopub.status.idle": "2024-02-20T08:59:07.116615Z",
     "shell.execute_reply": "2024-02-20T08:59:07.115797Z",
     "shell.execute_reply.started": "2024-02-20T08:59:07.109961Z"
    }
   },
   "outputs": [],
   "source": [
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:59:07.118280Z",
     "iopub.status.busy": "2024-02-20T08:59:07.117866Z",
     "iopub.status.idle": "2024-02-20T08:59:07.125474Z",
     "shell.execute_reply": "2024-02-20T08:59:07.124667Z",
     "shell.execute_reply.started": "2024-02-20T08:59:07.118249Z"
    }
   },
   "outputs": [],
   "source": [
    "new_train = train_datasets\n",
    "new_valid = valid_datasets\n",
    "new_test = test_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Spectrogram Transformer: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:59:07.126923Z",
     "iopub.status.busy": "2024-02-20T08:59:07.126551Z",
     "iopub.status.idle": "2024-02-20T08:59:21.395010Z",
     "shell.execute_reply": "2024-02-20T08:59:21.393999Z",
     "shell.execute_reply.started": "2024-02-20T08:59:07.126893Z"
    }
   },
   "outputs": [],
   "source": [
    "# # # AST Feature Extractor from transformer\n",
    "! pip -q install transformers\n",
    "from transformers import ASTFeatureExtractor, AutoModelForAudioClassification\n",
    "feature_extractor = ASTFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:59:21.397105Z",
     "iopub.status.busy": "2024-02-20T08:59:21.396473Z",
     "iopub.status.idle": "2024-02-20T08:59:21.405689Z",
     "shell.execute_reply": "2024-02-20T08:59:21.404648Z",
     "shell.execute_reply.started": "2024-02-20T08:59:21.397060Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    features = feature_extractor(audio_arrays, sampling_rate=feature_extractor.sampling_rate, truncation=True, return_attention_mask=True)\n",
    "    # add labels\n",
    "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = np.zeros((len(audio_arrays), len(labels)))\n",
    "    # fill numpy array\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "    features[\"labels\"] = labels_matrix.tolist()\n",
    "    return features\n",
    "\n",
    "# for dataset in datasets:\n",
    "#     dataset = dataset.map(prepare_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:59:21.407187Z",
     "iopub.status.busy": "2024-02-20T08:59:21.406913Z",
     "iopub.status.idle": "2024-02-20T08:59:21.420864Z",
     "shell.execute_reply": "2024-02-20T08:59:21.419956Z",
     "shell.execute_reply.started": "2024-02-20T08:59:21.407161Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_testset(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    features = feature_extractor(audio_arrays, sampling_rate=feature_extractor.sampling_rate, truncation=True, return_attention_mask=True)\n",
    "    # add labels\n",
    "#     labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "#     # create numpy array of shape (batch_size, num_labels)\n",
    "#     labels_matrix = np.zeros((len(audio_arrays), len(labels)))\n",
    "#     # fill numpy array\n",
    "#     for idx, label in enumerate(labels):\n",
    "#         labels_matrix[:, idx] = labels_batch[label]\n",
    "#     features[\"labels\"] = labels_matrix.tolist()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batched Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T08:59:21.422884Z",
     "iopub.status.busy": "2024-02-20T08:59:21.422181Z",
     "iopub.status.idle": "2024-02-20T09:01:01.347445Z",
     "shell.execute_reply": "2024-02-20T09:01:01.346506Z",
     "shell.execute_reply.started": "2024-02-20T08:59:21.422851Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(new_train)):\n",
    "    new_train[i] = new_train[i].map(prepare_dataset, batched=True, batch_size=100, remove_columns=[\"audio\", \"AS\", \"AR\", \"MR\", \"MS\", \"N\"], num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T09:01:01.348779Z",
     "iopub.status.busy": "2024-02-20T09:01:01.348475Z",
     "iopub.status.idle": "2024-02-20T09:01:12.773917Z",
     "shell.execute_reply": "2024-02-20T09:01:12.772971Z",
     "shell.execute_reply.started": "2024-02-20T09:01:01.348753Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(new_valid)):\n",
    "    new_valid[i] = new_valid[i].map(prepare_dataset, batched=True, batch_size=100, remove_columns=[\"audio\", \"AS\", \"AR\", \"MR\", \"MS\", \"N\"], num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T09:01:12.775323Z",
     "iopub.status.busy": "2024-02-20T09:01:12.775038Z",
     "iopub.status.idle": "2024-02-20T09:02:44.726031Z",
     "shell.execute_reply": "2024-02-20T09:02:44.725105Z",
     "shell.execute_reply.started": "2024-02-20T09:01:12.775297Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(new_test)):\n",
    "    new_test[i] = new_test[i].map(prepare_testset, batched=True, batch_size=100, remove_columns=[\"audio\"], num_proc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T09:02:44.727789Z",
     "iopub.status.busy": "2024-02-20T09:02:44.727451Z",
     "iopub.status.idle": "2024-02-20T09:03:07.705670Z",
     "shell.execute_reply": "2024-02-20T09:03:07.704800Z",
     "shell.execute_reply.started": "2024-02-20T09:02:44.727760Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "num_labels = len(id2label)\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=num_labels,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T09:04:02.535318Z",
     "iopub.status.busy": "2024-02-20T09:04:02.534571Z",
     "iopub.status.idle": "2024-02-20T09:04:02.578613Z",
     "shell.execute_reply": "2024-02-20T09:04:02.577872Z",
     "shell.execute_reply.started": "2024-02-20T09:04:02.535285Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "model_name = model_id.split(\"/\")[-1]\n",
    "batch_size = 4\n",
    "gradient_accumulation_steps = 1\n",
    "num_train_epochs = 10 # originally used 50 and 100 in local setting, increasing after 20 might crash in kaggle\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T09:04:09.651737Z",
     "iopub.status.busy": "2024-02-20T09:04:09.651363Z",
     "iopub.status.idle": "2024-02-20T09:04:09.660337Z",
     "shell.execute_reply": "2024-02-20T09:04:09.659371Z",
     "shell.execute_reply.started": "2024-02-20T09:04:09.651709Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'macro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation\n",
    "\n",
    "A weights and bias account must be activated to continue the training authorization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T09:04:10.134868Z",
     "iopub.status.busy": "2024-02-20T09:04:10.134573Z",
     "iopub.status.idle": "2024-02-20T09:04:10.142278Z",
     "shell.execute_reply": "2024-02-20T09:04:10.141338Z",
     "shell.execute_reply.started": "2024-02-20T09:04:10.134844Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "pt_ids = new_test[0]['patient_id']\n",
    "pt_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T09:04:10.442469Z",
     "iopub.status.busy": "2024-02-20T09:04:10.442183Z",
     "iopub.status.idle": "2024-02-20T09:29:14.294448Z",
     "shell.execute_reply": "2024-02-20T09:29:14.293250Z",
     "shell.execute_reply.started": "2024-02-20T09:04:10.442445Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer0 = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=new_train[0],\n",
    "    eval_dataset=new_valid[0],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer0.train()\n",
    "\n",
    "eval_f1_0 = trainer0.evaluate()['eval_f1']\n",
    "result = trainer0.predict(new_test[0])\n",
    "result = torch.tensor(result.predictions)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(result.squeeze().cpu())\n",
    "predictions0 = np.zeros(probs.shape)\n",
    "predictions0[np.where(probs >= 0.5)] = 1\n",
    "predictions0 = predictions0.astype(int)\n",
    "\n",
    "trainer1 = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=new_train[1],\n",
    "    eval_dataset=new_valid[1],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer1.train()\n",
    "\n",
    "eval_f1_1 = trainer1.evaluate()['eval_f1']\n",
    "result = trainer1.predict(new_test[1])\n",
    "result = torch.tensor(result.predictions)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(result.squeeze().cpu())\n",
    "predictions1 = np.zeros(probs.shape)\n",
    "predictions1[np.where(probs >= 0.5)] = 1\n",
    "predictions1 = predictions1.astype(int)\n",
    "\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=new_train[2],\n",
    "    eval_dataset=new_valid[2],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer2.train()\n",
    "\n",
    "eval_f1_2 = trainer2.evaluate()['eval_f1']\n",
    "result = trainer2.predict(new_test[2])\n",
    "result = torch.tensor(result.predictions)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(result.squeeze().cpu())\n",
    "predictions2 = np.zeros(probs.shape)\n",
    "predictions2[np.where(probs >= 0.5)] = 1\n",
    "predictions2 = predictions2.astype(int)\n",
    "\n",
    "\n",
    "trainer3 = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=new_train[3],\n",
    "    eval_dataset=new_valid[3],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer3.train()\n",
    "\n",
    "eval_f1_3 = trainer3.evaluate()['eval_f1']\n",
    "result = trainer3.predict(new_test[3])\n",
    "result = torch.tensor(result.predictions)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(result.squeeze().cpu())\n",
    "predictions3 = np.zeros(probs.shape)\n",
    "predictions3[np.where(probs >= 0.5)] = 1\n",
    "predictions3 = predictions3.astype(int)\n",
    "\n",
    "\n",
    "trainer4 = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=new_train[4],\n",
    "    eval_dataset=new_valid[4],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer4.train()\n",
    "\n",
    "eval_f1_4 = trainer4.evaluate()['eval_f1']\n",
    "result = trainer4.predict(new_test[4])\n",
    "result = torch.tensor(result.predictions)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(result.squeeze().cpu())\n",
    "predictions4 = np.zeros(probs.shape)\n",
    "predictions4[np.where(probs >= 0.5)] = 1\n",
    "predictions4 = predictions4.astype(int)\n",
    "\n",
    "\n",
    "trainer5 = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=new_train[5],\n",
    "    eval_dataset=new_valid[5],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer5.train()\n",
    "\n",
    "eval_f1_5 = trainer5.evaluate()['eval_f1']\n",
    "result = trainer5.predict(new_test[5])\n",
    "result = torch.tensor(result.predictions)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(result.squeeze().cpu())\n",
    "predictions5 = np.zeros(probs.shape)\n",
    "predictions5[np.where(probs >= 0.5)] = 1\n",
    "predictions5 = predictions5.astype(int)\n",
    "\n",
    "\n",
    "trainer6 = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=new_train[6],\n",
    "    eval_dataset=new_valid[6],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer6.train()\n",
    "\n",
    "eval_f1_6 = trainer6.evaluate()['eval_f1']\n",
    "result = trainer6.predict(new_test[6])\n",
    "result = torch.tensor(result.predictions)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(result.squeeze().cpu())\n",
    "predictions6 = np.zeros(probs.shape)\n",
    "predictions6[np.where(probs >= 0.5)] = 1\n",
    "predictions6 = predictions6.astype(int)\n",
    "\n",
    "trainer7 = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=new_train[7],\n",
    "    eval_dataset=new_valid[7],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer7.train()\n",
    "\n",
    "eval_f1_7 = trainer7.evaluate()['eval_f1']\n",
    "result = trainer7.predict(new_test[7])\n",
    "result = torch.tensor(result.predictions)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(result.squeeze().cpu())\n",
    "predictions7 = np.zeros(probs.shape)\n",
    "predictions7[np.where(probs >= 0.5)] = 1\n",
    "predictions7 = predictions7.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions: Weighted Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T09:29:14.297096Z",
     "iopub.status.busy": "2024-02-20T09:29:14.296694Z",
     "iopub.status.idle": "2024-02-20T09:29:14.310995Z",
     "shell.execute_reply": "2024-02-20T09:29:14.309945Z",
     "shell.execute_reply.started": "2024-02-20T09:29:14.297060Z"
    }
   },
   "outputs": [],
   "source": [
    "# print the f1 scores\n",
    "print(f\"eval_f1_0: {eval_f1_0}\")\n",
    "print(f\"eval_f1_1: {eval_f1_1}\")\n",
    "print(f\"eval_f1_2: {eval_f1_2}\")\n",
    "print(f\"eval_f1_3: {eval_f1_3}\")\n",
    "print(f\"eval_f1_4: {eval_f1_4}\")\n",
    "print(f\"eval_f1_5: {eval_f1_5}\")\n",
    "print(f\"eval_f1_6: {eval_f1_6}\")\n",
    "print(f\"eval_f1_7: {eval_f1_7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T09:29:14.312839Z",
     "iopub.status.busy": "2024-02-20T09:29:14.312450Z",
     "iopub.status.idle": "2024-02-20T09:29:14.321312Z",
     "shell.execute_reply": "2024-02-20T09:29:14.320379Z",
     "shell.execute_reply.started": "2024-02-20T09:29:14.312807Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform weighted majority voting of the predictions based on the trainer f1 scores\n",
    "predictions = (predictions0 * eval_f1_0 + predictions1 * eval_f1_1 + predictions2 * eval_f1_2 + predictions3 * eval_f1_3 + predictions4 * eval_f1_4 + predictions5 * eval_f1_5 + predictions6 * eval_f1_6 + predictions7 * eval_f1_7) / (eval_f1_0 + eval_f1_1 + eval_f1_2 + eval_f1_3 + eval_f1_4 + eval_f1_5 + eval_f1_6 + eval_f1_7)\n",
    "predictions = (predictions >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T09:29:14.325703Z",
     "iopub.status.busy": "2024-02-20T09:29:14.324294Z",
     "iopub.status.idle": "2024-02-20T09:29:14.338937Z",
     "shell.execute_reply": "2024-02-20T09:29:14.337721Z",
     "shell.execute_reply.started": "2024-02-20T09:29:14.325648Z"
    }
   },
   "outputs": [],
   "source": [
    "# if the first 4 predictions are 0 for a row, then the final prediction must be 1 for that row\n",
    "for i in range(predictions.shape[0]):\n",
    "    if np.sum(predictions[i, :4]) == 0:\n",
    "        predictions[i, 4] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T09:55:58.223128Z",
     "iopub.status.busy": "2024-02-20T09:55:58.222665Z",
     "iopub.status.idle": "2024-02-20T09:55:58.239125Z",
     "shell.execute_reply": "2024-02-20T09:55:58.237991Z",
     "shell.execute_reply.started": "2024-02-20T09:55:58.223099Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T09:56:10.769093Z",
     "iopub.status.busy": "2024-02-20T09:56:10.768716Z",
     "iopub.status.idle": "2024-02-20T09:56:10.787162Z",
     "shell.execute_reply": "2024-02-20T09:56:10.786080Z",
     "shell.execute_reply.started": "2024-02-20T09:56:10.769062Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a dataframe with the predictions\n",
    "submission = pd.DataFrame(predictions, columns=labels)\n",
    "submission[\"patient_id\"] = pt_ids\n",
    "submission = submission[[\"patient_id\", \"AS\", \"AR\", \"MR\", \"MS\", \"N\"]]\n",
    "submission\n",
    "\n",
    "# save the submission\n",
    "submission.to_csv(\"submission_AST_majority_voting_on_records.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7683890,
     "sourceId": 70055,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
