{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports and Prerequisites"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:54:01.318070Z","iopub.status.busy":"2024-02-20T08:54:01.317782Z","iopub.status.idle":"2024-02-20T08:55:07.733554Z","shell.execute_reply":"2024-02-20T08:55:07.732562Z","shell.execute_reply.started":"2024-02-20T08:54:01.318045Z"},"trusted":true},"outputs":[],"source":["# ! pip install datasets[audio]\n","! pip -q install accelerate -U\n","! pip -q install librosa==0.9.2\n","! pip -q install numpy==1.23.5\n","! pip -q install datasets==2.15\n","from datasets import Dataset, Audio\n","import librosa\n","import librosa.display\n","import IPython.display as ipd\n","import warnings\n","warnings.filterwarnings('ignore')\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:55:07.735960Z","iopub.status.busy":"2024-02-20T08:55:07.735392Z","iopub.status.idle":"2024-02-20T08:55:07.740614Z","shell.execute_reply":"2024-02-20T08:55:07.739613Z","shell.execute_reply.started":"2024-02-20T08:55:07.735933Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["# Kaggle Specific Working Directory"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:55:07.741841Z","iopub.status.busy":"2024-02-20T08:55:07.741570Z","iopub.status.idle":"2024-02-20T08:55:11.845000Z","shell.execute_reply":"2024-02-20T08:55:11.843756Z","shell.execute_reply.started":"2024-02-20T08:55:07.741809Z"},"trusted":true},"outputs":[],"source":["# delete all the files and directories recursively in the current working directory ...\n","\n","!rm -rf *\n","\n","# make directory ...\n","\n","!mkdir /kaggle/working/datasets\n","!mkdir /kaggle/working/datasets/train\n","!mkdir /kaggle/working/datasets/test\n","\n","#  reference original files without duplicating their content ...\n","\n","def all_files_in_folder_symlink(source_dir, target_dir):\n","    files = os.listdir(source_dir)\n","    \n","    for file in tqdm(files):\n","        source_file = os.path.join(source_dir, file)\n","        target_file = os.path.join(target_dir, file)\n","        os.symlink(source_file, target_file)\n","# symbolic link function as above ...\n","\n","\n","all_files_in_folder_symlink(\"/kaggle/input/biomed-datathon-bmefest2/train\",\"/kaggle/working/datasets/train\")\n","all_files_in_folder_symlink(\"/kaggle/input/biomed-datathon-bmefest2/test\",\"/kaggle/working/datasets/test\")\n","os.symlink(\"/kaggle/input/biomed-datathon-bmefest2/additional_metadata.csv\", \"/kaggle/working/datasets/additional_metadata.csv\")\n","os.symlink(\"/kaggle/input/biomed-datathon-bmefest2/sample_submission.csv\", \"/kaggle/working/datasets/sample_submission.csv\")\n","os.symlink(\"/kaggle/input/biomed-datathon-bmefest2/test_files.csv\", \"/kaggle/working/datasets/test_files.csv\")\n","os.symlink(\"/kaggle/input/biomed-datathon-bmefest2/train.csv\", \"/kaggle/working/datasets/train.csv\")\n","\n","os.symlink (\"/kaggle/input/biomed-datathon-bmefest2/train/085_sit_Tri6_06.wav\", \"/kaggle/working/datasets/train/085_sit_Tri.wav\")\n","\n","train_dir_path = \"/kaggle/working/datasets/train\"\n","test_dir_path = \"/kaggle/working/datasets/test\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:55:11.848694Z","iopub.status.busy":"2024-02-20T08:55:11.848291Z","iopub.status.idle":"2024-02-20T08:55:11.852845Z","shell.execute_reply":"2024-02-20T08:55:11.851866Z","shell.execute_reply.started":"2024-02-20T08:55:11.848665Z"},"trusted":true},"outputs":[],"source":["# train_dir_path = \"train\"\n","# test_dir_path = \"test\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:55:11.854448Z","iopub.status.busy":"2024-02-20T08:55:11.854044Z","iopub.status.idle":"2024-02-20T08:55:12.814482Z","shell.execute_reply":"2024-02-20T08:55:12.813550Z","shell.execute_reply.started":"2024-02-20T08:55:11.854417Z"},"trusted":true},"outputs":[],"source":["! tree -d"]},{"cell_type":"markdown","metadata":{},"source":["# Loading Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:55:12.816139Z","iopub.status.busy":"2024-02-20T08:55:12.815822Z","iopub.status.idle":"2024-02-20T08:55:12.868653Z","shell.execute_reply":"2024-02-20T08:55:12.867934Z","shell.execute_reply.started":"2024-02-20T08:55:12.816110Z"},"trusted":true},"outputs":[],"source":["# data = Dataset.from_csv(\"/kaggle/working/datasets/train.csv\")\n","data = pd.read_csv(\"/kaggle/working/datasets/train.csv\")\n","# data = pd.read_csv(\"train.csv\")\n","\n","# train test split\n","from sklearn.model_selection import train_test_split\n","train_data, valid_data = train_test_split(data, test_size=0.1, random_state=42)\n","\n","train_data = Dataset.from_pandas(train_data)\n","valid_data = Dataset.from_pandas(valid_data)\n","\n","test_data = pd.read_csv(\"/kaggle/working/datasets/test_files.csv\")\n","# test_data = pd.read_csv(\"test_files.csv\")\n","test_data = Dataset.from_pandas(test_data)"]},{"cell_type":"markdown","metadata":{},"source":["# File Path to Audio Mapping"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:55:12.869864Z","iopub.status.busy":"2024-02-20T08:55:12.869583Z","iopub.status.idle":"2024-02-20T08:55:12.875718Z","shell.execute_reply":"2024-02-20T08:55:12.874790Z","shell.execute_reply.started":"2024-02-20T08:55:12.869816Z"},"trusted":true},"outputs":[],"source":["def from_train_path_to_audio(path):\n","    path = str(train_dir_path) + \"/\" + path + \".wav\"\n","    aud, sr = librosa.load(path, sr=None)\n","    return dict({\"array\": aud, \"sampling_rate\": sr})\n","\n","def from_test_path_to_audio(path):\n","    path = str(test_dir_path) + \"/\" + path + \".wav\"\n","    aud, sr = librosa.load(path, sr=None)\n","    return dict({\"array\": aud, \"sampling_rate\": sr})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:55:12.877114Z","iopub.status.busy":"2024-02-20T08:55:12.876841Z","iopub.status.idle":"2024-02-20T08:55:28.105797Z","shell.execute_reply":"2024-02-20T08:55:28.104814Z","shell.execute_reply.started":"2024-02-20T08:55:12.877080Z"},"trusted":true},"outputs":[],"source":["recording_columns = [\"recording_1\", \"recording_2\", \"recording_3\", \"recording_4\", \"recording_5\", \"recording_6\", \"recording_7\", \"recording_8\"]\n","labels = [\"AS\", \"AR\", \"MR\", \"MS\", \"N\"]\n","\n","# for each recording column, replace the recording column element path with the audio object using the from_train_path_to_audio function and create a new dataset\n","for recording_column in recording_columns:\n","    train_data = train_data.map(lambda x: {recording_column: from_train_path_to_audio(x[recording_column])}, remove_columns=[recording_column])\n","\n","# do the same for valid data\n","for recording_column in recording_columns:\n","    valid_data = valid_data.map(lambda x: {recording_column: from_train_path_to_audio(x[recording_column])}, remove_columns=[recording_column])\n","\n","for recording_column in recording_columns:\n","    test_data = test_data.map(lambda x: {recording_column: from_test_path_to_audio(x[recording_column])}, remove_columns=[recording_column])\n"]},{"cell_type":"markdown","metadata":{},"source":["# Resampling to 16KHz"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:55:28.107546Z","iopub.status.busy":"2024-02-20T08:55:28.107180Z","iopub.status.idle":"2024-02-20T08:56:23.037716Z","shell.execute_reply":"2024-02-20T08:56:23.036687Z","shell.execute_reply.started":"2024-02-20T08:55:28.107513Z"},"trusted":true},"outputs":[],"source":["# convert to 16kHz\n","for recording_column in recording_columns:\n","    train_data = train_data.cast_column(recording_column, Audio(sampling_rate=16000))\n","train_data[0]\n","\n","# same for valid data\n","for recording_column in recording_columns:\n","    valid_data = valid_data.cast_column(recording_column, Audio(sampling_rate=16000))\n","valid_data[0]\n","\n","# same for valid data\n","for recording_column in recording_columns:\n","    test_data = test_data.cast_column(recording_column, Audio(sampling_rate=16000))\n","test_data[0]"]},{"cell_type":"markdown","metadata":{},"source":["# Creating Recording Wise Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:56:23.042151Z","iopub.status.busy":"2024-02-20T08:56:23.041861Z","iopub.status.idle":"2024-02-20T08:59:07.108627Z","shell.execute_reply":"2024-02-20T08:59:07.107723Z","shell.execute_reply.started":"2024-02-20T08:56:23.042127Z"},"trusted":true},"outputs":[],"source":["# there are 8 recordings for each row, we will create 8 different datasets for each recording, and drop the other recordings\n","train_datasets = []\n","for recording_column in recording_columns:\n","    train_dataset = train_data.map(lambda x: {\"audio\": x[recording_column]}, remove_columns=recording_columns)\n","    train_datasets.append(train_dataset)\n","train_datasets[0]\n","\n","# same for valid data\n","valid_datasets = []\n","for recording_column in recording_columns:\n","    valid_dataset = valid_data.map(lambda x: {\"audio\": x[recording_column]}, remove_columns=recording_columns)\n","    valid_datasets.append(valid_dataset)\n","valid_datasets[0]\n","\n","# same for valid data\n","test_datasets = []\n","for recording_column in recording_columns:\n","    test_dataset = test_data.map(lambda x: {\"audio\": x[recording_column]}, remove_columns=recording_columns)\n","    test_datasets.append(test_dataset)\n","test_datasets[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:59:07.109983Z","iopub.status.busy":"2024-02-20T08:59:07.109732Z","iopub.status.idle":"2024-02-20T08:59:07.116615Z","shell.execute_reply":"2024-02-20T08:59:07.115797Z","shell.execute_reply.started":"2024-02-20T08:59:07.109961Z"},"trusted":true},"outputs":[],"source":["id2label = {idx:label for idx, label in enumerate(labels)}\n","label2id = {label:idx for idx, label in enumerate(labels)}\n","label2id"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:59:07.118280Z","iopub.status.busy":"2024-02-20T08:59:07.117866Z","iopub.status.idle":"2024-02-20T08:59:07.125474Z","shell.execute_reply":"2024-02-20T08:59:07.124667Z","shell.execute_reply.started":"2024-02-20T08:59:07.118249Z"},"trusted":true},"outputs":[],"source":["new_train = train_datasets\n","new_valid = valid_datasets\n","new_test = test_datasets"]},{"cell_type":"markdown","metadata":{},"source":["# Audio Spectrogram Transformer: Feature Extraction"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:59:07.126923Z","iopub.status.busy":"2024-02-20T08:59:07.126551Z","iopub.status.idle":"2024-02-20T08:59:21.395010Z","shell.execute_reply":"2024-02-20T08:59:21.393999Z","shell.execute_reply.started":"2024-02-20T08:59:07.126893Z"},"trusted":true},"outputs":[],"source":["# # # AST Feature Extractor from transformer\n","! pip -q install transformers\n","from transformers import ASTFeatureExtractor, AutoModelForAudioClassification\n","feature_extractor = ASTFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:59:21.397105Z","iopub.status.busy":"2024-02-20T08:59:21.396473Z","iopub.status.idle":"2024-02-20T08:59:21.405689Z","shell.execute_reply":"2024-02-20T08:59:21.404648Z","shell.execute_reply.started":"2024-02-20T08:59:21.397060Z"},"trusted":true},"outputs":[],"source":["def prepare_dataset(examples):\n","    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n","    features = feature_extractor(audio_arrays, sampling_rate=feature_extractor.sampling_rate, truncation=True, return_attention_mask=True)\n","    # add labels\n","    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n","    # create numpy array of shape (batch_size, num_labels)\n","    labels_matrix = np.zeros((len(audio_arrays), len(labels)))\n","    # fill numpy array\n","    for idx, label in enumerate(labels):\n","        labels_matrix[:, idx] = labels_batch[label]\n","    features[\"labels\"] = labels_matrix.tolist()\n","    return features\n","\n","# for dataset in datasets:\n","#     dataset = dataset.map(prepare_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:59:21.407187Z","iopub.status.busy":"2024-02-20T08:59:21.406913Z","iopub.status.idle":"2024-02-20T08:59:21.420864Z","shell.execute_reply":"2024-02-20T08:59:21.419956Z","shell.execute_reply.started":"2024-02-20T08:59:21.407161Z"},"trusted":true},"outputs":[],"source":["def prepare_testset(examples):\n","    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n","    features = feature_extractor(audio_arrays, sampling_rate=feature_extractor.sampling_rate, truncation=True, return_attention_mask=True)\n","    # add labels\n","#     labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n","#     # create numpy array of shape (batch_size, num_labels)\n","#     labels_matrix = np.zeros((len(audio_arrays), len(labels)))\n","#     # fill numpy array\n","#     for idx, label in enumerate(labels):\n","#         labels_matrix[:, idx] = labels_batch[label]\n","#     features[\"labels\"] = labels_matrix.tolist()\n","    return features"]},{"cell_type":"markdown","metadata":{},"source":["# Batched Data Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T08:59:21.422884Z","iopub.status.busy":"2024-02-20T08:59:21.422181Z","iopub.status.idle":"2024-02-20T09:01:01.347445Z","shell.execute_reply":"2024-02-20T09:01:01.346506Z","shell.execute_reply.started":"2024-02-20T08:59:21.422851Z"},"trusted":true},"outputs":[],"source":["for i in range(len(new_train)):\n","    new_train[i] = new_train[i].map(prepare_dataset, batched=True, batch_size=100, remove_columns=[\"audio\", \"AS\", \"AR\", \"MR\", \"MS\", \"N\"], num_proc=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T09:01:01.348779Z","iopub.status.busy":"2024-02-20T09:01:01.348475Z","iopub.status.idle":"2024-02-20T09:01:12.773917Z","shell.execute_reply":"2024-02-20T09:01:12.772971Z","shell.execute_reply.started":"2024-02-20T09:01:01.348753Z"},"trusted":true},"outputs":[],"source":["for i in range(len(new_valid)):\n","    new_valid[i] = new_valid[i].map(prepare_dataset, batched=True, batch_size=100, remove_columns=[\"audio\", \"AS\", \"AR\", \"MR\", \"MS\", \"N\"], num_proc=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T09:01:12.775323Z","iopub.status.busy":"2024-02-20T09:01:12.775038Z","iopub.status.idle":"2024-02-20T09:02:44.726031Z","shell.execute_reply":"2024-02-20T09:02:44.725105Z","shell.execute_reply.started":"2024-02-20T09:01:12.775297Z"},"trusted":true},"outputs":[],"source":["for i in range(len(new_test)):\n","    new_test[i] = new_test[i].map(prepare_testset, batched=True, batch_size=100, remove_columns=[\"audio\"], num_proc=1)"]},{"cell_type":"markdown","metadata":{},"source":["# Model and Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T09:02:44.727789Z","iopub.status.busy":"2024-02-20T09:02:44.727451Z","iopub.status.idle":"2024-02-20T09:03:07.705670Z","shell.execute_reply":"2024-02-20T09:03:07.704800Z","shell.execute_reply.started":"2024-02-20T09:02:44.727760Z"},"trusted":true},"outputs":[],"source":["model_id = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n","num_labels = len(id2label)\n","model = AutoModelForAudioClassification.from_pretrained(\n","    model_id,\n","    num_labels=num_labels,\n","    label2id=label2id,\n","    id2label=id2label,\n","    ignore_mismatched_sizes=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T09:04:02.535318Z","iopub.status.busy":"2024-02-20T09:04:02.534571Z","iopub.status.idle":"2024-02-20T09:04:02.578613Z","shell.execute_reply":"2024-02-20T09:04:02.577872Z","shell.execute_reply.started":"2024-02-20T09:04:02.535285Z"},"trusted":true},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","model_name = model_id.split(\"/\")[-1]\n","batch_size = 4\n","gradient_accumulation_steps = 1\n","num_train_epochs = 10 # originally used 50 and 100 in local setting, increasing after 20 might crash in kaggle\n","\n","training_args = TrainingArguments(\n","    f\"{model_name}-finetuned\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=5e-4,\n","    per_device_train_batch_size=batch_size,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=num_train_epochs,\n","    warmup_ratio=0.1,\n","    logging_steps=10,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\",\n","    fp16=True,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T09:04:09.651737Z","iopub.status.busy":"2024-02-20T09:04:09.651363Z","iopub.status.idle":"2024-02-20T09:04:09.660337Z","shell.execute_reply":"2024-02-20T09:04:09.659371Z","shell.execute_reply.started":"2024-02-20T09:04:09.651709Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n","from transformers import EvalPrediction\n","import torch\n","    \n","# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n","def multi_label_metrics(predictions, labels, threshold=0.5):\n","    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n","    sigmoid = torch.nn.Sigmoid()\n","    probs = sigmoid(torch.Tensor(predictions))\n","    # next, use threshold to turn them into integer predictions\n","    y_pred = np.zeros(probs.shape)\n","    y_pred[np.where(probs >= threshold)] = 1\n","    # finally, compute metrics\n","    y_true = labels\n","    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n","    roc_auc = roc_auc_score(y_true, y_pred, average = 'macro')\n","    accuracy = accuracy_score(y_true, y_pred)\n","    # return as dictionary\n","    metrics = {'f1': f1_micro_average,\n","               'roc_auc': roc_auc,\n","               'accuracy': accuracy}\n","    return metrics\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = p.predictions[0] if isinstance(p.predictions, \n","            tuple) else p.predictions\n","    result = multi_label_metrics(\n","        predictions=preds, \n","        labels=p.label_ids)\n","    return result"]},{"cell_type":"markdown","metadata":{},"source":["# Training and Validation\n","\n","A weights and bias account must be activated to continue the training authorization process"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T09:04:10.134868Z","iopub.status.busy":"2024-02-20T09:04:10.134573Z","iopub.status.idle":"2024-02-20T09:04:10.142278Z","shell.execute_reply":"2024-02-20T09:04:10.141338Z","shell.execute_reply.started":"2024-02-20T09:04:10.134844Z"},"trusted":true},"outputs":[],"source":["import gc\n","pt_ids = new_test[0]['patient_id']\n","pt_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T09:04:10.442469Z","iopub.status.busy":"2024-02-20T09:04:10.442183Z","iopub.status.idle":"2024-02-20T09:29:14.294448Z","shell.execute_reply":"2024-02-20T09:29:14.293250Z","shell.execute_reply.started":"2024-02-20T09:04:10.442445Z"},"trusted":true},"outputs":[],"source":["from transformers import Trainer\n","\n","trainer0 = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=new_train[0],\n","    eval_dataset=new_valid[0],\n","    tokenizer=feature_extractor,\n","    compute_metrics=compute_metrics,\n",")\n","trainer0.train()\n","\n","eval_f1_0 = trainer0.evaluate()['eval_f1']\n","result = trainer0.predict(new_test[0])\n","result = torch.tensor(result.predictions)\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(result.squeeze().cpu())\n","predictions0 = np.zeros(probs.shape)\n","predictions0[np.where(probs >= 0.5)] = 1\n","predictions0 = predictions0.astype(int)\n","\n","trainer1 = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=new_train[1],\n","    eval_dataset=new_valid[1],\n","    tokenizer=feature_extractor,\n","    compute_metrics=compute_metrics,\n",")\n","trainer1.train()\n","\n","eval_f1_1 = trainer1.evaluate()['eval_f1']\n","result = trainer1.predict(new_test[1])\n","result = torch.tensor(result.predictions)\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(result.squeeze().cpu())\n","predictions1 = np.zeros(probs.shape)\n","predictions1[np.where(probs >= 0.5)] = 1\n","predictions1 = predictions1.astype(int)\n","\n","\n","trainer2 = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=new_train[2],\n","    eval_dataset=new_valid[2],\n","    tokenizer=feature_extractor,\n","    compute_metrics=compute_metrics,\n",")\n","trainer2.train()\n","\n","eval_f1_2 = trainer2.evaluate()['eval_f1']\n","result = trainer2.predict(new_test[2])\n","result = torch.tensor(result.predictions)\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(result.squeeze().cpu())\n","predictions2 = np.zeros(probs.shape)\n","predictions2[np.where(probs >= 0.5)] = 1\n","predictions2 = predictions2.astype(int)\n","\n","\n","trainer3 = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=new_train[3],\n","    eval_dataset=new_valid[3],\n","    tokenizer=feature_extractor,\n","    compute_metrics=compute_metrics,\n",")\n","trainer3.train()\n","\n","eval_f1_3 = trainer3.evaluate()['eval_f1']\n","result = trainer3.predict(new_test[3])\n","result = torch.tensor(result.predictions)\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(result.squeeze().cpu())\n","predictions3 = np.zeros(probs.shape)\n","predictions3[np.where(probs >= 0.5)] = 1\n","predictions3 = predictions3.astype(int)\n","\n","\n","trainer4 = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=new_train[4],\n","    eval_dataset=new_valid[4],\n","    tokenizer=feature_extractor,\n","    compute_metrics=compute_metrics,\n",")\n","trainer4.train()\n","\n","eval_f1_4 = trainer4.evaluate()['eval_f1']\n","result = trainer4.predict(new_test[4])\n","result = torch.tensor(result.predictions)\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(result.squeeze().cpu())\n","predictions4 = np.zeros(probs.shape)\n","predictions4[np.where(probs >= 0.5)] = 1\n","predictions4 = predictions4.astype(int)\n","\n","\n","trainer5 = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=new_train[5],\n","    eval_dataset=new_valid[5],\n","    tokenizer=feature_extractor,\n","    compute_metrics=compute_metrics,\n",")\n","trainer5.train()\n","\n","eval_f1_5 = trainer5.evaluate()['eval_f1']\n","result = trainer5.predict(new_test[5])\n","result = torch.tensor(result.predictions)\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(result.squeeze().cpu())\n","predictions5 = np.zeros(probs.shape)\n","predictions5[np.where(probs >= 0.5)] = 1\n","predictions5 = predictions5.astype(int)\n","\n","\n","trainer6 = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=new_train[6],\n","    eval_dataset=new_valid[6],\n","    tokenizer=feature_extractor,\n","    compute_metrics=compute_metrics,\n",")\n","trainer6.train()\n","\n","eval_f1_6 = trainer6.evaluate()['eval_f1']\n","result = trainer6.predict(new_test[6])\n","result = torch.tensor(result.predictions)\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(result.squeeze().cpu())\n","predictions6 = np.zeros(probs.shape)\n","predictions6[np.where(probs >= 0.5)] = 1\n","predictions6 = predictions6.astype(int)\n","\n","trainer7 = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=new_train[7],\n","    eval_dataset=new_valid[7],\n","    tokenizer=feature_extractor,\n","    compute_metrics=compute_metrics,\n",")\n","trainer7.train()\n","\n","eval_f1_7 = trainer7.evaluate()['eval_f1']\n","result = trainer7.predict(new_test[7])\n","result = torch.tensor(result.predictions)\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(result.squeeze().cpu())\n","predictions7 = np.zeros(probs.shape)\n","predictions7[np.where(probs >= 0.5)] = 1\n","predictions7 = predictions7.astype(int)"]},{"cell_type":"markdown","metadata":{},"source":["# Predictions: Weighted Majority Voting"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T09:29:14.297096Z","iopub.status.busy":"2024-02-20T09:29:14.296694Z","iopub.status.idle":"2024-02-20T09:29:14.310995Z","shell.execute_reply":"2024-02-20T09:29:14.309945Z","shell.execute_reply.started":"2024-02-20T09:29:14.297060Z"},"trusted":true},"outputs":[],"source":["# print the f1 scores\n","print(f\"eval_f1_0: {eval_f1_0}\")\n","print(f\"eval_f1_1: {eval_f1_1}\")\n","print(f\"eval_f1_2: {eval_f1_2}\")\n","print(f\"eval_f1_3: {eval_f1_3}\")\n","print(f\"eval_f1_4: {eval_f1_4}\")\n","print(f\"eval_f1_5: {eval_f1_5}\")\n","print(f\"eval_f1_6: {eval_f1_6}\")\n","print(f\"eval_f1_7: {eval_f1_7}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T09:29:14.312839Z","iopub.status.busy":"2024-02-20T09:29:14.312450Z","iopub.status.idle":"2024-02-20T09:29:14.321312Z","shell.execute_reply":"2024-02-20T09:29:14.320379Z","shell.execute_reply.started":"2024-02-20T09:29:14.312807Z"},"trusted":true},"outputs":[],"source":["# perform weighted majority voting of the predictions based on the trainer f1 scores\n","predictions = (predictions0 * eval_f1_0 + predictions1 * eval_f1_1 + predictions2 * eval_f1_2 + predictions3 * eval_f1_3 + predictions4 * eval_f1_4 + predictions5 * eval_f1_5 + predictions6 * eval_f1_6 + predictions7 * eval_f1_7) / (eval_f1_0 + eval_f1_1 + eval_f1_2 + eval_f1_3 + eval_f1_4 + eval_f1_5 + eval_f1_6 + eval_f1_7)\n","predictions = (predictions >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T09:29:14.325703Z","iopub.status.busy":"2024-02-20T09:29:14.324294Z","iopub.status.idle":"2024-02-20T09:29:14.338937Z","shell.execute_reply":"2024-02-20T09:29:14.337721Z","shell.execute_reply.started":"2024-02-20T09:29:14.325648Z"},"trusted":true},"outputs":[],"source":["# if the first 4 predictions are 0 for a row, then the final prediction must be 1 for that row\n","for i in range(predictions.shape[0]):\n","    if np.sum(predictions[i, :4]) == 0:\n","        predictions[i, 4] = 1 "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T09:55:58.223128Z","iopub.status.busy":"2024-02-20T09:55:58.222665Z","iopub.status.idle":"2024-02-20T09:55:58.239125Z","shell.execute_reply":"2024-02-20T09:55:58.237991Z","shell.execute_reply.started":"2024-02-20T09:55:58.223099Z"},"trusted":true},"outputs":[],"source":["predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T09:56:10.769093Z","iopub.status.busy":"2024-02-20T09:56:10.768716Z","iopub.status.idle":"2024-02-20T09:56:10.787162Z","shell.execute_reply":"2024-02-20T09:56:10.786080Z","shell.execute_reply.started":"2024-02-20T09:56:10.769062Z"},"trusted":true},"outputs":[],"source":["# create a dataframe with the predictions\n","submission = pd.DataFrame(predictions, columns=labels)\n","submission[\"patient_id\"] = pt_ids\n","submission = submission[[\"patient_id\", \"AS\", \"AR\", \"MR\", \"MS\", \"N\"]]\n","submission\n","\n","# save the submission\n","submission.to_csv(\"submission_AST_majority_voting_on_records.csv\", index=False)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7683890,"sourceId":70055,"sourceType":"competition"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
